{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c07135794d94435993a3eb02ae1552bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfcb3f3bf2cc4cd0bff2cd68d6684482",
              "IPY_MODEL_4c6c9c171726431c90eb196e6b0418cd",
              "IPY_MODEL_a15429dbdd12439e8af2d029db9f1087"
            ],
            "layout": "IPY_MODEL_663551dfce6a415c9b5d24863a81d44d"
          }
        },
        "cfcb3f3bf2cc4cd0bff2cd68d6684482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54b5b2083e441afb44c44002823165b",
            "placeholder": "​",
            "style": "IPY_MODEL_6b8271a02e53441eac5a150e79ef356d",
            "value": "config.json: 100%"
          }
        },
        "4c6c9c171726431c90eb196e6b0418cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cb637f81c94abf9664e5fa2911a9ff",
            "max": 457,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f3f825ab5094e8089c90f9b39b8cfef",
            "value": 457
          }
        },
        "a15429dbdd12439e8af2d029db9f1087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec0f7fdd303425095ff2283e98d38bf",
            "placeholder": "​",
            "style": "IPY_MODEL_77d72ecc423446d2b244f5f0109d3111",
            "value": " 457/457 [00:00&lt;00:00, 34.0kB/s]"
          }
        },
        "663551dfce6a415c9b5d24863a81d44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f54b5b2083e441afb44c44002823165b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8271a02e53441eac5a150e79ef356d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51cb637f81c94abf9664e5fa2911a9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f3f825ab5094e8089c90f9b39b8cfef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec0f7fdd303425095ff2283e98d38bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d72ecc423446d2b244f5f0109d3111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "366131129ae245d9976972d82b4c2fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b073a08780bb491cbc74a13d5acf99d9",
              "IPY_MODEL_e569cb8f6b8c43a89fa7601cdda1f075",
              "IPY_MODEL_6b4dbaa17f824faa81b61ae649ddb0ae"
            ],
            "layout": "IPY_MODEL_910c6e1066de4209bc244017343c71bf"
          }
        },
        "b073a08780bb491cbc74a13d5acf99d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ff46a32b4745d4b66089a1a553cd3a",
            "placeholder": "​",
            "style": "IPY_MODEL_251f07b51a6d4ce7bbe42226dcef03e2",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e569cb8f6b8c43a89fa7601cdda1f075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d682a37154054fc0bc8f8450b0814130",
            "max": 11275562268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856f84aa77464ff48647b56dc60db965",
            "value": 11275562268
          }
        },
        "6b4dbaa17f824faa81b61ae649ddb0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc7ce53a62ec4ffab58259498e6dacc8",
            "placeholder": "​",
            "style": "IPY_MODEL_2f1db0ba26464d489a8a24bed836b913",
            "value": " 11.3G/11.3G [00:31&lt;00:00, 451MB/s]"
          }
        },
        "910c6e1066de4209bc244017343c71bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ff46a32b4745d4b66089a1a553cd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "251f07b51a6d4ce7bbe42226dcef03e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d682a37154054fc0bc8f8450b0814130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856f84aa77464ff48647b56dc60db965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc7ce53a62ec4ffab58259498e6dacc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1db0ba26464d489a8a24bed836b913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b96f1b1baaa42bd8b14818477dd55b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42083f24deb44664ba3cb37f6607ea59",
              "IPY_MODEL_9bad26bc54b847a2bb7db1034653736f",
              "IPY_MODEL_d93996bbe4734131be08ec737f334b1b"
            ],
            "layout": "IPY_MODEL_39cf16cf96da41f99e35be7cc0a8f5a0"
          }
        },
        "42083f24deb44664ba3cb37f6607ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1094f06b803c41c6a12f88ceb5698402",
            "placeholder": "​",
            "style": "IPY_MODEL_b4a174ed86f84c53a59bbaebf4e29d8a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9bad26bc54b847a2bb7db1034653736f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3586ee4229444688f8759568b7b25e8",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f93894d2dd41e092ca9a3c9b2c0964",
            "value": 24
          }
        },
        "d93996bbe4734131be08ec737f334b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9a34f64cb04d32aba28acc3dd975f6",
            "placeholder": "​",
            "style": "IPY_MODEL_11f04dca4ff44b20a8d91eb4fb0a0abf",
            "value": " 24.0/24.0 [00:00&lt;00:00, 2.15kB/s]"
          }
        },
        "39cf16cf96da41f99e35be7cc0a8f5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1094f06b803c41c6a12f88ceb5698402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a174ed86f84c53a59bbaebf4e29d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3586ee4229444688f8759568b7b25e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f93894d2dd41e092ca9a3c9b2c0964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e9a34f64cb04d32aba28acc3dd975f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f04dca4ff44b20a8d91eb4fb0a0abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86f1bba24e94356b093fabcec13985b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d499d6cf4ec4425eb5f7683c14c68a4d",
              "IPY_MODEL_988f51add80d4c08a06644f3233c3428",
              "IPY_MODEL_0e6106b5dd984c02971ceac5eaa00f49"
            ],
            "layout": "IPY_MODEL_09de039905234365be45b6e8ec4a4215"
          }
        },
        "d499d6cf4ec4425eb5f7683c14c68a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c3522dfbec460a84b9317d43a2d934",
            "placeholder": "​",
            "style": "IPY_MODEL_99a310af75ec4835983b94cf1e0c971f",
            "value": "spiece.model: 100%"
          }
        },
        "988f51add80d4c08a06644f3233c3428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30384b02077b45899893b619c753c934",
            "max": 237990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_421d38f9f2994c37b0cf64b2dd601063",
            "value": 237990
          }
        },
        "0e6106b5dd984c02971ceac5eaa00f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0ac2998b9c43918b03d5f5cd103788",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b5ef77f54542969569e2ee2a65e7e1",
            "value": " 238k/238k [00:00&lt;00:00, 13.8MB/s]"
          }
        },
        "09de039905234365be45b6e8ec4a4215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c3522dfbec460a84b9317d43a2d934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a310af75ec4835983b94cf1e0c971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30384b02077b45899893b619c753c934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421d38f9f2994c37b0cf64b2dd601063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd0ac2998b9c43918b03d5f5cd103788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b5ef77f54542969569e2ee2a65e7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8284a4b1c7634b04a2f6cc8e8b06f7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4abc89a76964da59799b0b4d0486909",
              "IPY_MODEL_d92a153f47e74b0b91dd5fa7f1f670f0",
              "IPY_MODEL_b33c4407276c4976adc9f6d554e9e648"
            ],
            "layout": "IPY_MODEL_4d4c9f7a18974626bb10498a81e606cc"
          }
        },
        "a4abc89a76964da59799b0b4d0486909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322468af57eb42a8a17566c1eae9c8f0",
            "placeholder": "​",
            "style": "IPY_MODEL_490e120137064b149096963643a8b065",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d92a153f47e74b0b91dd5fa7f1f670f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1725ea828fd247abb6a688d23d6b7b24",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a0955571dbc42d78b0dc780f34079dd",
            "value": 1786
          }
        },
        "b33c4407276c4976adc9f6d554e9e648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9469683ac04d4bdbadbbaee0780e2a8c",
            "placeholder": "​",
            "style": "IPY_MODEL_22dbf44d01134694b17a7f2efd6f72a7",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "4d4c9f7a18974626bb10498a81e606cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322468af57eb42a8a17566c1eae9c8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490e120137064b149096963643a8b065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1725ea828fd247abb6a688d23d6b7b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a0955571dbc42d78b0dc780f34079dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9469683ac04d4bdbadbbaee0780e2a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22dbf44d01134694b17a7f2efd6f72a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ProtFlamingo with ESM-2 Embeddings (Pure PPI)"
      ],
      "metadata": {
        "id": "lTgNrBvYVs8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data + Preprocess"
      ],
      "metadata": {
        "id": "bPsj0NXNtMSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szm_USwqeGh2",
        "outputId": "768a309e-8546-439a-f049-fd4a4976271e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Programmable Biology Group/Srikar/Code/flamingo-pep-gen/ppi-mlo915')"
      ],
      "metadata": {
        "id": "8fm5Tfj1eboF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opaOXn34ewCo",
        "outputId": "aa9672e2-c091-4fc7-b5d1-7d3628e87e5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ppigpt_test_merged_MI0915_LTPHTP_oct3_2023.csv\tppigpt_train_merged_MI0915_LTPHTP_oct3_2023.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('ppigpt_train_merged_MI0915_LTPHTP_oct3_2023.csv',index_col=0)\n",
        "test = pd.read_csv('ppigpt_test_merged_MI0915_LTPHTP_oct3_2023.csv',index_col=0)\n",
        "\n",
        "train = train[['seq_1','seq_2']]\n",
        "test = test[['seq_1','seq_2']]"
      ],
      "metadata": {
        "id": "rFNEP29TexKt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ArnHwq7Ge8Wn",
        "outputId": "77dc0f40-5a6b-42ec-de8d-755c22f626d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                seq_1  \\\n",
              "1   MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...   \n",
              "7   MQAEIKADIIVEAMEVLVNHILYVRGIYPSHIFKMKRMYNSPIYVS...   \n",
              "31  MTYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNM...   \n",
              "52  MTDETAHPTQSASKQESAALKQTGDDQQESQQQRGYTNYNNGSNYT...   \n",
              "57  MRSVTNAFGNSGELNDQVDETGYRKFDIHEGILFCIELSETMFKES...   \n",
              "\n",
              "                                                seq_2  \n",
              "1   MPGARDALCHQALQLLAELCARGALEHDSCQDFIYHLRDRARPRLR...  \n",
              "7   MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...  \n",
              "31  MVNQGQPQPNLYDKHINMFPPARARESSHKLGNANSDRHGLPAQNI...  \n",
              "52  MWNPILLDTSSFSFQKHVSGVFLQVRNATKRAAGSRTSMKDSAGRR...  \n",
              "57  MNENEYDNFDDLDDLLDEDPTKLDEAEPDDVQAKGSVYNDSENKEK...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30829896-f23e-419d-ae94-2dd7bab01b38\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq_1</th>\n",
              "      <th>seq_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MKKWSSTDLGAAADPLQKDTCPDPLDGDPNSRPPPAKPQLSTAKSR...</td>\n",
              "      <td>MPGARDALCHQALQLLAELCARGALEHDSCQDFIYHLRDRARPRLR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MQAEIKADIIVEAMEVLVNHILYVRGIYPSHIFKMKRMYNSPIYVS...</td>\n",
              "      <td>MGSALENYVNQVRTLSASGSYRELAEELPESLSLLARNWSILDNVL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>MTYTTRQIGAKNTLEYKVYIEKDGKPVSAFHDIPLYADKENNIFNM...</td>\n",
              "      <td>MVNQGQPQPNLYDKHINMFPPARARESSHKLGNANSDRHGLPAQNI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>MTDETAHPTQSASKQESAALKQTGDDQQESQQQRGYTNYNNGSNYT...</td>\n",
              "      <td>MWNPILLDTSSFSFQKHVSGVFLQVRNATKRAAGSRTSMKDSAGRR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>MRSVTNAFGNSGELNDQVDETGYRKFDIHEGILFCIELSETMFKES...</td>\n",
              "      <td>MNENEYDNFDDLDDLLDEDPTKLDEAEPDDVQAKGSVYNDSENKEK...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30829896-f23e-419d-ae94-2dd7bab01b38')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30829896-f23e-419d-ae94-2dd7bab01b38 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30829896-f23e-419d-ae94-2dd7bab01b38');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b964ae2-419a-4bca-b678-d62426b2b0e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b964ae2-419a-4bca-b678-d62426b2b0e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b964ae2-419a-4bca-b678-d62426b2b0e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions + Gated Cross Attn + Perceiver Resampler"
      ],
      "metadata": {
        "id": "QsWWUVuFs8MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from transformers import RobertaModel  # Assuming use of Hugging Face's transformer models\n",
        "\n",
        "\n",
        "\n",
        "# Helper Functions\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def set_module_requires_grad_(module, requires_grad):\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "\n",
        "def freeze_model_and_make_eval_(model):\n",
        "    model.eval()\n",
        "    set_module_requires_grad_(model, False)\n",
        "\n",
        "# LayerNorm class\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.gain = nn.Parameter(torch.ones(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gain * (x - mean) / (std + self.eps)\n",
        "\n",
        "# Residual class\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "# SwiGLU activation function\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.silu(x[..., :x.shape[-1] // 2]) * x[..., x.shape[-1] // 2:]\n",
        "\n",
        "# Transformer Block class\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, mlp_dim):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, heads)\n",
        "        self.ln2 = LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            SwiGLU(),\n",
        "            nn.Linear(mlp_dim, dim)\n",
        "        )\n",
        "        self.residual = Residual(self.ln1)\n",
        "        self.feedforward = Residual(self.ln2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.residual(self.attn(x, x, x)[0])\n",
        "        x = self.feedforward(self.mlp(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "tDQcNuG8n5nK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ypy2EZWLTogB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421c4f21-3f24-4779-fbd8-52f8ef8fa452"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops-exts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDcDefLVW5-h",
        "outputId": "554d24e4-fd46-48d7-983e-db5d1913ef9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops-exts\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Collecting einops>=0.4 (from einops-exts)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops, einops-exts\n",
            "Successfully installed einops-0.7.0 einops-exts-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops_exts import rearrange_many, repeat_many\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def FeedForward(dim, mult = 4):\n",
        "    inner_dim = int(dim * mult)\n",
        "    return nn.Sequential(\n",
        "        nn.LayerNorm(dim),\n",
        "        nn.Linear(dim, inner_dim, bias = False),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(inner_dim, dim, bias = False)\n",
        "    )\n",
        "\n",
        "class PerceiverAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        dim_head = 64,\n",
        "        heads = 8\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm_media = nn.LayerNorm(dim)\n",
        "        self.norm_latents = nn.LayerNorm(dim)\n",
        "\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
        "\n",
        "    def forward(self, x, latents):\n",
        "        \"\"\"\n",
        "        einstein notation\n",
        "        b - batch\n",
        "        t - time\n",
        "        n - sequence\n",
        "        d - dimension\n",
        "        \"\"\"\n",
        "        x = self.norm_media(x)\n",
        "        latents = self.norm_latents(latents)\n",
        "\n",
        "        b, m, h = *x.shape[:2], self.heads\n",
        "\n",
        "        q = self.to_q(latents)\n",
        "\n",
        "        # the paper differs from Perceiver in which they also concat the key / values derived from the latents to be attended to\n",
        "        kv_input = torch.cat((x, latents), dim = -2)\n",
        "        k, v = self.to_kv(kv_input).chunk(2, dim = -1)\n",
        "\n",
        "        q, k, v = rearrange_many((q, k, v), 'b t n (h d) -> b h t n d', h = h)\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        # attention\n",
        "\n",
        "        sim = einsum('... i d, ... j d  -> ... i j', q, k)\n",
        "\n",
        "        sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
        "        attn = sim.softmax(dim = -1)\n",
        "\n",
        "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
        "        out = rearrange(out, 'b h t n d -> b t n (h d)', h = h)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class PerceiverResampler(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        depth,\n",
        "        dim_head = 64,\n",
        "        heads = 8,\n",
        "        num_latents = 64,\n",
        "        num_media_embeds = 4,\n",
        "        ff_mult = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "        self.media_pos_emb = nn.Parameter(torch.randn(num_media_embeds, 1, dim))\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PerceiverAttention(dim = dim, dim_head = dim_head, heads = heads),\n",
        "                FeedForward(dim = dim, mult = ff_mult)\n",
        "            ]))\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.ndim == 3:\n",
        "            x = rearrange(x, 'b n d -> b 1 n d')\n",
        "            print(x.shape)\n",
        "\n",
        "        times = x.shape[1]\n",
        "        print(self.media_pos_emb.shape)\n",
        "        x = x + self.media_pos_emb[:times]\n",
        "        # print(x.shape)\n",
        "        # print(self.media_pos_emb[:times].shape)\n",
        "\n",
        "        latents = repeat(self.latents, 'n d -> b m n d', b = x.shape[0], m = x.shape[1])\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            latents = attn(x, latents) + latents\n",
        "            latents = ff(latents) + latents\n",
        "\n",
        "        return self.norm(latents)\n",
        "\n",
        "# gated cross attention\n",
        "\n",
        "class MaskedCrossAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        dim_head = 64,\n",
        "        heads = 8,\n",
        "        only_attend_immediate_media = True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias = False)\n",
        "\n",
        "        # whether for text to only attend to immediate preceding image, or all images\n",
        "\n",
        "        self.only_attend_immediate_media = only_attend_immediate_media\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        media,\n",
        "        media_locations = None\n",
        "    ):\n",
        "        b, t, m = media.shape[:3]\n",
        "        h = self.heads\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        q = self.to_q(x)\n",
        "        media = rearrange(media, 'b t n d -> b (t n) d')\n",
        "\n",
        "        k, v = self.to_kv(media).chunk(2, dim = -1)\n",
        "        q, k, v = rearrange_many((q, k, v), 'b n (h d) -> b h n d', h = h)\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum('... i d, ... j d -> ... i j', q, k)\n",
        "\n",
        "        if exists(media_locations):\n",
        "            text_time = media_locations.cumsum(dim = -1) # at each boolean of True, increment the time counter (relative to media time)\n",
        "            media_time = torch.arange(t, device = x.device) + 1\n",
        "\n",
        "            # text time must equal media time if only attending to most immediate image\n",
        "            # otherwise, as long as text time is greater than media time (if attending to all previous images / media)\n",
        "            mask_op = torch.eq if self.only_attend_immediate_media else torch.ge\n",
        "\n",
        "            text_to_media_mask = mask_op(rearrange(text_time, 'b i -> b 1 i 1'), repeat(media_time, 'j -> 1 1 1 (j m)', m = m))\n",
        "            sim = sim.masked_fill(~text_to_media_mask, -torch.finfo(sim.dtype).max)\n",
        "\n",
        "        sim = sim - sim.amax(dim = -1, keepdim = True).detach()\n",
        "        attn = sim.softmax(dim = -1)\n",
        "\n",
        "        if exists(media_locations) and self.only_attend_immediate_media:\n",
        "            # any text without a preceding media needs to have attention zeroed out\n",
        "            text_without_media_mask = text_time == 0\n",
        "            text_without_media_mask = rearrange(text_without_media_mask, 'b i -> b 1 i 1')\n",
        "            attn = attn.masked_fill(text_without_media_mask, 0.)\n",
        "\n",
        "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "class GatedCrossAttentionBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        dim_head = 64,\n",
        "        heads = 8,\n",
        "        ff_mult = 4,\n",
        "        only_attend_immediate_media = True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.attn = MaskedCrossAttention(dim = dim, dim_head = dim_head, heads = heads, only_attend_immediate_media = only_attend_immediate_media)\n",
        "        self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "        self.ff = FeedForward(dim, mult = ff_mult)\n",
        "        self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        media,                  # media tensor, encoded by perceiver resample - (batch, time, latents, dim)\n",
        "        media_locations = None  # boolean tensor indicating positions of media - (batch, sequence)\n",
        "    ):\n",
        "        x = self.attn(x, media, media_locations = media_locations) * self.attn_gate.tanh() + x\n",
        "        x = self.ff(x) * self.ff_gate.tanh()  + x\n",
        "        return x"
      ],
      "metadata": {
        "id": "RwoWz-10p__C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ProtFlamingo and Model Train"
      ],
      "metadata": {
        "id": "Up2gOmc-tC09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbAz-2X3tUfw",
        "outputId": "514701c2-caae-4840-b05c-6e32df3c00bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fair-esm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbOuDn6dtdsN",
        "outputId": "2f0d7cbe-d8ee-456f-82e2-ed2c6da3cc53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjtOxpDNu7I2",
        "outputId": "263fb46c-99e4-4a8c-ad9c-6f33b84101e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "qK2-ed1SUsHb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.sample(n=4, random_state=np.random.RandomState())\n",
        "test = test.sample(n=4, random_state = np.random.RandomState())"
      ],
      "metadata": {
        "id": "GwyAz-VQUYen"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece"
      ],
      "metadata": {
        "id": "h3hhSN5Nvpvw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import esm\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n",
        "# Load ProtT5 model\n",
        "protT5_model = T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "protT5_tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "\n",
        "# Load ESM-2 model for embeddings\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model.eval()\n",
        "if torch.cuda.is_available():\n",
        "    esm_model.cuda()\n",
        "\n",
        "# Function to generate embeddings for a list of sequences\n",
        "def generate_esm_embeddings(rbp_seqs):\n",
        "    rbp_seqs_dict = {}\n",
        "    for seq in tqdm(rbp_seqs):\n",
        "        # Convert sequence to model input format\n",
        "        batch_labels, batch_strs, batch_tokens = batch_converter([(\"\", seq)])\n",
        "        batch_tokens = batch_tokens.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        with torch.no_grad():\n",
        "            results = esm_model(batch_tokens, repr_layers=[33])\n",
        "        token_representations = results[\"representations\"][33]\n",
        "        seq_len = (batch_tokens != alphabet.padding_idx).sum(1).item()\n",
        "        rbp_seqs_dict[seq] = token_representations[0, 1:seq_len-1].cpu()\n",
        "    return rbp_seqs_dict\n",
        "\n",
        "# Custom Dataset\n",
        "class ProteinInteractionDataset(Dataset):\n",
        "    def __init__(self, dataframe, esm_embeddings):\n",
        "        self.dataframe = dataframe\n",
        "        self.esm_embeddings = esm_embeddings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prot1_seq, prot2_seq = self.dataframe.iloc[idx]['seq_1'], self.dataframe.iloc[idx]['seq_2']\n",
        "        prot1_embedding = self.esm_embeddings[prot1_seq]\n",
        "        prot2_tokenized = protT5_tokenizer.encode(prot2_seq, return_tensors=\"pt\").squeeze()\n",
        "        return prot1_embedding, prot2_tokenized\n"
      ],
      "metadata": {
        "id": "faTh1zfnnTZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "c07135794d94435993a3eb02ae1552bc",
            "cfcb3f3bf2cc4cd0bff2cd68d6684482",
            "4c6c9c171726431c90eb196e6b0418cd",
            "a15429dbdd12439e8af2d029db9f1087",
            "663551dfce6a415c9b5d24863a81d44d",
            "f54b5b2083e441afb44c44002823165b",
            "6b8271a02e53441eac5a150e79ef356d",
            "51cb637f81c94abf9664e5fa2911a9ff",
            "4f3f825ab5094e8089c90f9b39b8cfef",
            "dec0f7fdd303425095ff2283e98d38bf",
            "77d72ecc423446d2b244f5f0109d3111",
            "366131129ae245d9976972d82b4c2fde",
            "b073a08780bb491cbc74a13d5acf99d9",
            "e569cb8f6b8c43a89fa7601cdda1f075",
            "6b4dbaa17f824faa81b61ae649ddb0ae",
            "910c6e1066de4209bc244017343c71bf",
            "c2ff46a32b4745d4b66089a1a553cd3a",
            "251f07b51a6d4ce7bbe42226dcef03e2",
            "d682a37154054fc0bc8f8450b0814130",
            "856f84aa77464ff48647b56dc60db965",
            "cc7ce53a62ec4ffab58259498e6dacc8",
            "2f1db0ba26464d489a8a24bed836b913",
            "4b96f1b1baaa42bd8b14818477dd55b6",
            "42083f24deb44664ba3cb37f6607ea59",
            "9bad26bc54b847a2bb7db1034653736f",
            "d93996bbe4734131be08ec737f334b1b",
            "39cf16cf96da41f99e35be7cc0a8f5a0",
            "1094f06b803c41c6a12f88ceb5698402",
            "b4a174ed86f84c53a59bbaebf4e29d8a",
            "d3586ee4229444688f8759568b7b25e8",
            "72f93894d2dd41e092ca9a3c9b2c0964",
            "3e9a34f64cb04d32aba28acc3dd975f6",
            "11f04dca4ff44b20a8d91eb4fb0a0abf",
            "e86f1bba24e94356b093fabcec13985b",
            "d499d6cf4ec4425eb5f7683c14c68a4d",
            "988f51add80d4c08a06644f3233c3428",
            "0e6106b5dd984c02971ceac5eaa00f49",
            "09de039905234365be45b6e8ec4a4215",
            "02c3522dfbec460a84b9317d43a2d934",
            "99a310af75ec4835983b94cf1e0c971f",
            "30384b02077b45899893b619c753c934",
            "421d38f9f2994c37b0cf64b2dd601063",
            "fd0ac2998b9c43918b03d5f5cd103788",
            "d9b5ef77f54542969569e2ee2a65e7e1",
            "8284a4b1c7634b04a2f6cc8e8b06f7c5",
            "a4abc89a76964da59799b0b4d0486909",
            "d92a153f47e74b0b91dd5fa7f1f670f0",
            "b33c4407276c4976adc9f6d554e9e648",
            "4d4c9f7a18974626bb10498a81e606cc",
            "322468af57eb42a8a17566c1eae9c8f0",
            "490e120137064b149096963643a8b065",
            "1725ea828fd247abb6a688d23d6b7b24",
            "0a0955571dbc42d78b0dc780f34079dd",
            "9469683ac04d4bdbadbbaee0780e2a8c",
            "22dbf44d01134694b17a7f2efd6f72a7"
          ]
        },
        "outputId": "b368b101-4674-4a90-c6ba-6e97c7e21a59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/457 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c07135794d94435993a3eb02ae1552bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/11.3G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "366131129ae245d9976972d82b4c2fde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b96f1b1baaa42bd8b14818477dd55b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86f1bba24e94356b093fabcec13985b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8284a4b1c7634b04a2f6cc8e8b06f7c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzndaIpYfzR5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import pad\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Find the longest sequence in the batch\n",
        "    max_length = max(max(prot1_emb.size(0), prot2_tok.size(0)) for prot1_emb, prot2_tok in batch)\n",
        "\n",
        "    prot1_embeddings_padded = []\n",
        "    prot2_tokenized_padded = []\n",
        "\n",
        "    for prot1_emb, prot2_tok in batch:\n",
        "        # Pad each sequence to the max_length\n",
        "        prot1_emb_padded = pad(prot1_emb, (0, 0, 0, max_length - prot1_emb.size(0)))\n",
        "        prot2_tok_padded = pad(prot2_tok, (0, max_length - prot2_tok.size(0)))\n",
        "\n",
        "        prot1_embeddings_padded.append(prot1_emb_padded)\n",
        "        prot2_tokenized_padded.append(prot2_tok_padded)\n",
        "\n",
        "    return torch.stack(prot1_embeddings_padded), torch.stack(prot2_tokenized_padded)\n",
        "\n",
        "# Prepare  train and test data\n",
        "train_df = train # train DataFrame\n",
        "test_df = test  # test DataFrame\n",
        "\n",
        "esm_embeddings = generate_esm_embeddings(pd.concat([train_df['seq_1'], test_df['seq_1']]).unique())\n",
        "train_dataset = ProteinInteractionDataset(train_df, esm_embeddings)\n",
        "test_dataset = ProteinInteractionDataset(test_df, esm_embeddings)\n",
        "\n",
        "# Use collate_fn in DataLoader\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgri5hB8UxfB",
        "outputId": "1276a123-61fb-419b-9592-661e431130b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:03<00:00,  2.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4lEfJySU7Oi",
        "outputId": "b919101e-724c-4a58-c084-9bee37f761a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(x)\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gate = x.chunk(2, dim=-1)\n",
        "        return F.silu(gate) * x\n",
        "\n",
        "class ParallelTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_head=64, heads=8, ff_mult=4):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "        attn_inner_dim = dim_head * heads\n",
        "        ff_inner_dim = dim * ff_mult\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, 2* ff_mult * dim),\n",
        "            SwiGLU(),\n",
        "            nn.Linear(ff_mult * dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Input to ParallelTransformerBlock:\", x.shape)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        print(\"After LayerNorm:\", x.shape)\n",
        "\n",
        "        x = x.permute(1, 0, 2)  # Rearrange for nn.MultiheadAttention\n",
        "        print(\"After permute for MultiheadAttention:\", x.shape)\n",
        "\n",
        "        attn_output, _ = self.attn(x, x, x)\n",
        "        print(\"After MultiheadAttention:\", attn_output.shape)\n",
        "\n",
        "        x = attn_output + x\n",
        "        print(\"After adding attn_output:\", x.shape)\n",
        "\n",
        "        x = x.permute(1, 0, 2)  # Rearrange back\n",
        "        print(\"After permute back:\", x.shape)\n",
        "\n",
        "        # ff_output = self.ff(x)\n",
        "        # print(\"After FeedForward:\", ff_output.shape)\n",
        "        ff_output = x\n",
        "        for layer in self.ff:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                print(\"Input to Linear Layer:\", ff_output.shape)\n",
        "                ff_output = layer(ff_output)\n",
        "                print(\"Output from Linear Layer:\", ff_output.shape)\n",
        "            else:\n",
        "                # Assuming SwiGLU or other non-linear layers don't change shape\n",
        "                ff_output = layer(ff_output)\n",
        "\n",
        "        output = ff_output + x\n",
        "        print(\"Output from ParallelTransformerBlock:\", output.shape)\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "2DvByxwAW-rQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\").config.d_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00XlIu_l5F2",
        "outputId": "67f0de67-1c65-47af-d79e-f477b26506de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ProtFlamingo(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        num_tokens,\n",
        "        depth,\n",
        "        dim_head=64,\n",
        "        heads=8,\n",
        "        ff_mult=4,\n",
        "        cross_attn_every=3,\n",
        "        perceiver_num_latents=64,\n",
        "        perceiver_depth=2,\n",
        "        only_attend_immediate_media=True,\n",
        "        protein_mode=False, motif_mode=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Add flags for protein and motif modes\n",
        "        self.protein_mode = protein_mode\n",
        "        self.motif_mode = motif_mode\n",
        "\n",
        "        # Apply layer freezing based on the mode\n",
        "        self._apply_layer_freezing()\n",
        "\n",
        "\n",
        "        # ProtT5 model\n",
        "        self.protT5 = T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "        self.prot_dim = self.protT5.config.d_model\n",
        "        self.dim = train_dataloader.dataset[0][0].shape[1]\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "\n",
        "\n",
        "        # Check if adjustment is needed and add a linear layer for embedding size adjustment\n",
        "        if self.protT5.config.d_model != 1280:\n",
        "            self.embedding_adjustment = nn.Linear(self.protT5.config.d_model, 1280)\n",
        "        else:\n",
        "            self.embedding_adjustment = None\n",
        "\n",
        "        # Perceiver Resampler for processing ESM-2 embeddings\n",
        "        self.perceiver_resampler = PerceiverResampler(\n",
        "            dim=self.dim,\n",
        "            depth=perceiver_depth,\n",
        "            dim_head=dim_head,\n",
        "            heads=heads,\n",
        "            num_latents=perceiver_num_latents\n",
        "        )\n",
        "        print('perceiver done...')\n",
        "        print(self.dim)\n",
        "\n",
        "        # Flamingo-like layers with Gated Cross Attention and ParallelTransformerBlock\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for ind in range(depth):\n",
        "            parallel_transformer_block = ParallelTransformerBlock(dim=self.dim, dim_head=dim_head, heads=heads, ff_mult=ff_mult)\n",
        "            self.layers.append(parallel_transformer_block)\n",
        "\n",
        "            if ind % cross_attn_every == 0:\n",
        "                gated_cross_attention_block = GatedCrossAttentionBlock(\n",
        "                    dim=self.dim,\n",
        "                    dim_head=dim_head,\n",
        "                    heads=heads,\n",
        "                    only_attend_immediate_media=only_attend_immediate_media\n",
        "                )\n",
        "                self.layers.append(gated_cross_attention_block)\n",
        "\n",
        "        print('gated cross attn done..')\n",
        "\n",
        "\n",
        "        # Output layer\n",
        "        self.to_logits = nn.Linear(self.dim, num_tokens)\n",
        "\n",
        "    def _apply_layer_freezing(self):\n",
        "        # Check if in protein or motif mode\n",
        "        if self.protein_mode or self.motif_mode:\n",
        "            # In protein/motif mode, freeze everything but perceiver and gated cross attention\n",
        "            self._freeze_all_layers()\n",
        "            self._unfreeze_layers(self.perceiver_resampler)\n",
        "            for _, layer in self.layers:\n",
        "                if isinstance(layer, GatedCrossAttentionBlock):\n",
        "                    self._unfreeze_layers(layer)\n",
        "        else:\n",
        "            # Unfreeze all layers in other modes\n",
        "            self._unfreeze_layers(self)\n",
        "\n",
        "    def _freeze_all_layers(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def _unfreeze_layers(self, module):\n",
        "        for param in module.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, prot1_embeddings, generated_sequence):\n",
        "        # Process prot1 embeddings through perceiver resampler\n",
        "        processed_prot1_embeddings = self.perceiver_resampler(prot1_embeddings)\n",
        "        print('processed_prot1 embeddings')\n",
        "\n",
        "        # Prepare the generated sequence for input to the model\n",
        "        #generated_sequence_tensor = torch.tensor([[generated_sequence]], dtype=torch.long).to(prot1_embeddings.device)\n",
        "        generated_sequence_tensor = generated_sequence.to(prot1_embeddings.device)\n",
        "\n",
        "        print('prepare gen seq')\n",
        "\n",
        "\n",
        "        # Embed the generated sequence using the ProtT5 decoder's embedding layer\n",
        "        sequence_emb = self.protT5.decoder.embed_tokens(generated_sequence_tensor) * (self.dim ** 0.5)\n",
        "        # Apply the embedding size adjustment if the layer was initialized\n",
        "        if self.embedding_adjustment is not None:\n",
        "            sequence_emb = self.embedding_adjustment(sequence_emb)\n",
        "        print('embed generated seq')\n",
        "\n",
        "        # Process the sequence through the layers of the model\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, ParallelTransformerBlock):\n",
        "                print('parelleltransfomr')\n",
        "                print(sequence_emb.shape)\n",
        "                sequence_emb = layer(sequence_emb)\n",
        "            elif isinstance(layer, GatedCrossAttentionBlock):\n",
        "                print('gated cross attn')\n",
        "                print(sequence_emb.shape)\n",
        "                sequence_emb = layer(sequence_emb, processed_prot1_embeddings)\n",
        "        print('process gen seq thru model layers')\n",
        "\n",
        "        # Output the logits for the next token\n",
        "        next_token_logits = self.to_logits(sequence_emb[:, -1, :])\n",
        "\n",
        "        return next_token_logits\n"
      ],
      "metadata": {
        "id": "lLM3qSP9q4mR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_epoch(model, data_loader, optimizer, criterion, device):\n",
        "#     model.train()\n",
        "#     total_loss = 0\n",
        "\n",
        "#     for input_protein_embedding, target_sequences in data_loader:\n",
        "#         input_protein_embedding = input_protein_embedding.to(device).squeeze(1)  # Adjust dimensions if needed\n",
        "\n",
        "#         batch_loss = 0\n",
        "\n",
        "#         for target_sequence in target_sequences:  # Iterate over each sequence in the batch\n",
        "#             optimizer.zero_grad()\n",
        "#             loss = 0\n",
        "\n",
        "#             # Start with a start token\n",
        "#             generated_sequence = 3 ## token ids\n",
        "#             print(generated_sequence)\n",
        "\n",
        "#             for i in range(1, target_sequence.size(0)):  # Iterate over each token in the sequence\n",
        "#                 target_token = target_sequence[i].item()  # Now this should be a single element\n",
        "\n",
        "#                 # Predict the next token\n",
        "#                 next_token_logits = model(input_protein_embedding, generated_sequence)\n",
        "\n",
        "#                 # Compute loss for the current step\n",
        "#                 loss += criterion(next_token_logits, torch.tensor([target_token], dtype=torch.long).to(device))\n",
        "\n",
        "#                 # Update the generated sequence\n",
        "#                 generated_sequence.append(target_token)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             batch_loss += loss.item() / target_sequence.size(0)  # Normalize by sequence length\n",
        "\n",
        "#         total_loss += batch_loss / len(target_sequences)  # Normalize by batch size\n",
        "\n",
        "#     return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "uVhzHCmy7R3h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for input_protein_embedding, target_sequences in data_loader:\n",
        "        # Move input and target sequences to the device\n",
        "        input_protein_embedding = input_protein_embedding.to(device).squeeze(1)\n",
        "        target_sequences = target_sequences.to(device).squeeze(1)\n",
        "\n",
        "        # Initialize generated_sequence for the entire batch with the start token\n",
        "        start_token_id = 3  # Replace with your actual start token ID\n",
        "        batch_size = input_protein_embedding.size(0)\n",
        "        generated_sequence = torch.full((batch_size, 1), start_token_id, dtype=torch.long).to(device)  # Shape [batch_size, 1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = 0\n",
        "\n",
        "        for i in range(1, target_sequences.size(1)):  # Iterate over each token in the sequence\n",
        "            # Predict the next token\n",
        "            next_token_logits = model(input_protein_embedding, generated_sequence)\n",
        "\n",
        "            # Flatten output for loss calculation\n",
        "            next_token_logits = next_token_logits.view(-1, next_token_logits.size(-1))\n",
        "\n",
        "            # Compute loss for the current step\n",
        "            current_token = target_sequences[:, i]  # Shape [batch_size]\n",
        "            loss += criterion(next_token_logits, current_token)\n",
        "\n",
        "            # Update the generated sequence for the next iteration\n",
        "            current_token = current_token.unsqueeze(1)  # Add sequence length dimension\n",
        "            generated_sequence = torch.cat([generated_sequence, current_token], dim=1)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss = loss.item() / target_sequences.size(1)  # Normalize by sequence length\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "VU_keTs7E9LE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model, optimizer, and other training components\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example parameters\n",
        "num_tokens = protT5_tokenizer.vocab_size\n",
        "depth = 2  # Adjust based on model complexity and computational resources\n",
        "\n",
        "# Instantiate the model\n",
        "model = ProtFlamingo(\n",
        "    num_tokens=num_tokens,\n",
        "    depth=depth\n",
        ").to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYQtIbj96AKF",
        "outputId": "384803aa-df13-4849-8a2b-6e00488412dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perceiver done...\n",
            "1280\n",
            "gated cross attn done..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "batch_size = 2\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "7GFNeIj65A5L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "K1kULaU26WpV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader.dataset[0][0].shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaasn4u9f2dy",
        "outputId": "1d79644c-db1a-4992-ffa7-265ed8096430"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(model, train_dataloader,optimizer,criterion,device)\n",
        "    print(f\"Epoch {epoch}: Training Loss: {train_loss}\")\n",
        "\n",
        "# Save the model after training\n",
        "torch.save(model.state_dict(), 'prot_flamingo_model.pth')\n",
        "\n",
        "# Define inference function for generating protein sequences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FNxGVUqIXLbb",
        "outputId": "a97391ec-efb5-458e-ed03-f9b6cd39fc07"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 62, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 62, 1280])\n",
            "After LayerNorm: torch.Size([2, 62, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([62, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([62, 2, 1280])\n",
            "After adding attn_output: torch.Size([62, 2, 1280])\n",
            "After permute back: torch.Size([2, 62, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 62, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 62, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 62, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 62, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 62, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 62, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 62, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 62, 1280])\n",
            "After LayerNorm: torch.Size([2, 62, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([62, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([62, 2, 1280])\n",
            "After adding attn_output: torch.Size([62, 2, 1280])\n",
            "After permute back: torch.Size([2, 62, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 62, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 62, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 62, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 62, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 62, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 63, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 63, 1280])\n",
            "After LayerNorm: torch.Size([2, 63, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([63, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([63, 2, 1280])\n",
            "After adding attn_output: torch.Size([63, 2, 1280])\n",
            "After permute back: torch.Size([2, 63, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 63, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 63, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 63, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 63, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 63, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 63, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 63, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 63, 1280])\n",
            "After LayerNorm: torch.Size([2, 63, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([63, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([63, 2, 1280])\n",
            "After adding attn_output: torch.Size([63, 2, 1280])\n",
            "After permute back: torch.Size([2, 63, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 63, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 63, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 63, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 63, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 63, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 64, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 64, 1280])\n",
            "After LayerNorm: torch.Size([2, 64, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([64, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([64, 2, 1280])\n",
            "After adding attn_output: torch.Size([64, 2, 1280])\n",
            "After permute back: torch.Size([2, 64, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 64, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 64, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 64, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 64, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 64, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 64, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 64, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 64, 1280])\n",
            "After LayerNorm: torch.Size([2, 64, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([64, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([64, 2, 1280])\n",
            "After adding attn_output: torch.Size([64, 2, 1280])\n",
            "After permute back: torch.Size([2, 64, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 64, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 64, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 64, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 64, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 64, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 65, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 65, 1280])\n",
            "After LayerNorm: torch.Size([2, 65, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([65, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([65, 2, 1280])\n",
            "After adding attn_output: torch.Size([65, 2, 1280])\n",
            "After permute back: torch.Size([2, 65, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 65, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 65, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 65, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 65, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 65, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 65, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 65, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 65, 1280])\n",
            "After LayerNorm: torch.Size([2, 65, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([65, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([65, 2, 1280])\n",
            "After adding attn_output: torch.Size([65, 2, 1280])\n",
            "After permute back: torch.Size([2, 65, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 65, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 65, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 65, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 65, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 65, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 66, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 66, 1280])\n",
            "After LayerNorm: torch.Size([2, 66, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([66, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([66, 2, 1280])\n",
            "After adding attn_output: torch.Size([66, 2, 1280])\n",
            "After permute back: torch.Size([2, 66, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 66, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 66, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 66, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 66, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 66, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 66, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 66, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 66, 1280])\n",
            "After LayerNorm: torch.Size([2, 66, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([66, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([66, 2, 1280])\n",
            "After adding attn_output: torch.Size([66, 2, 1280])\n",
            "After permute back: torch.Size([2, 66, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 66, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 66, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 66, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 66, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 66, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 67, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 67, 1280])\n",
            "After LayerNorm: torch.Size([2, 67, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([67, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([67, 2, 1280])\n",
            "After adding attn_output: torch.Size([67, 2, 1280])\n",
            "After permute back: torch.Size([2, 67, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 67, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 67, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 67, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 67, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 67, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 67, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 67, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 67, 1280])\n",
            "After LayerNorm: torch.Size([2, 67, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([67, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([67, 2, 1280])\n",
            "After adding attn_output: torch.Size([67, 2, 1280])\n",
            "After permute back: torch.Size([2, 67, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 67, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 67, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 67, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 67, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 67, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 68, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 68, 1280])\n",
            "After LayerNorm: torch.Size([2, 68, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([68, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([68, 2, 1280])\n",
            "After adding attn_output: torch.Size([68, 2, 1280])\n",
            "After permute back: torch.Size([2, 68, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 68, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 68, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 68, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 68, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 68, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 68, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 68, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 68, 1280])\n",
            "After LayerNorm: torch.Size([2, 68, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([68, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([68, 2, 1280])\n",
            "After adding attn_output: torch.Size([68, 2, 1280])\n",
            "After permute back: torch.Size([2, 68, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 68, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 68, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 68, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 68, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 68, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 69, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 69, 1280])\n",
            "After LayerNorm: torch.Size([2, 69, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([69, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([69, 2, 1280])\n",
            "After adding attn_output: torch.Size([69, 2, 1280])\n",
            "After permute back: torch.Size([2, 69, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 69, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 69, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 69, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 69, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 69, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 69, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 69, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 69, 1280])\n",
            "After LayerNorm: torch.Size([2, 69, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([69, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([69, 2, 1280])\n",
            "After adding attn_output: torch.Size([69, 2, 1280])\n",
            "After permute back: torch.Size([2, 69, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 69, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 69, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 69, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 69, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 69, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 70, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 70, 1280])\n",
            "After LayerNorm: torch.Size([2, 70, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([70, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([70, 2, 1280])\n",
            "After adding attn_output: torch.Size([70, 2, 1280])\n",
            "After permute back: torch.Size([2, 70, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 70, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 70, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 70, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 70, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 70, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 70, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 70, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 70, 1280])\n",
            "After LayerNorm: torch.Size([2, 70, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([70, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([70, 2, 1280])\n",
            "After adding attn_output: torch.Size([70, 2, 1280])\n",
            "After permute back: torch.Size([2, 70, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 70, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 70, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 70, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 70, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 70, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 71, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 71, 1280])\n",
            "After LayerNorm: torch.Size([2, 71, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([71, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([71, 2, 1280])\n",
            "After adding attn_output: torch.Size([71, 2, 1280])\n",
            "After permute back: torch.Size([2, 71, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 71, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 71, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 71, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 71, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 71, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 71, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 71, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 71, 1280])\n",
            "After LayerNorm: torch.Size([2, 71, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([71, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([71, 2, 1280])\n",
            "After adding attn_output: torch.Size([71, 2, 1280])\n",
            "After permute back: torch.Size([2, 71, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 71, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 71, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 71, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 71, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 71, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 72, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 72, 1280])\n",
            "After LayerNorm: torch.Size([2, 72, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([72, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([72, 2, 1280])\n",
            "After adding attn_output: torch.Size([72, 2, 1280])\n",
            "After permute back: torch.Size([2, 72, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 72, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 72, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 72, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 72, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 72, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 72, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 72, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 72, 1280])\n",
            "After LayerNorm: torch.Size([2, 72, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([72, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([72, 2, 1280])\n",
            "After adding attn_output: torch.Size([72, 2, 1280])\n",
            "After permute back: torch.Size([2, 72, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 72, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 72, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 72, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 72, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 72, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 73, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 73, 1280])\n",
            "After LayerNorm: torch.Size([2, 73, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([73, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([73, 2, 1280])\n",
            "After adding attn_output: torch.Size([73, 2, 1280])\n",
            "After permute back: torch.Size([2, 73, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 73, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 73, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 73, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 73, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 73, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 73, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 73, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 73, 1280])\n",
            "After LayerNorm: torch.Size([2, 73, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([73, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([73, 2, 1280])\n",
            "After adding attn_output: torch.Size([73, 2, 1280])\n",
            "After permute back: torch.Size([2, 73, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 73, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 73, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 73, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 73, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 73, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 74, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 74, 1280])\n",
            "After LayerNorm: torch.Size([2, 74, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([74, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([74, 2, 1280])\n",
            "After adding attn_output: torch.Size([74, 2, 1280])\n",
            "After permute back: torch.Size([2, 74, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 74, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 74, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 74, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 74, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 74, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 74, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 74, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 74, 1280])\n",
            "After LayerNorm: torch.Size([2, 74, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([74, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([74, 2, 1280])\n",
            "After adding attn_output: torch.Size([74, 2, 1280])\n",
            "After permute back: torch.Size([2, 74, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 74, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 74, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 74, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 74, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 74, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 75, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 75, 1280])\n",
            "After LayerNorm: torch.Size([2, 75, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([75, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([75, 2, 1280])\n",
            "After adding attn_output: torch.Size([75, 2, 1280])\n",
            "After permute back: torch.Size([2, 75, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 75, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 75, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 75, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 75, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 75, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 75, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 75, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 75, 1280])\n",
            "After LayerNorm: torch.Size([2, 75, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([75, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([75, 2, 1280])\n",
            "After adding attn_output: torch.Size([75, 2, 1280])\n",
            "After permute back: torch.Size([2, 75, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 75, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 75, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 75, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 75, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 75, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 76, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 76, 1280])\n",
            "After LayerNorm: torch.Size([2, 76, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([76, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([76, 2, 1280])\n",
            "After adding attn_output: torch.Size([76, 2, 1280])\n",
            "After permute back: torch.Size([2, 76, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 76, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 76, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 76, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 76, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 76, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 76, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 76, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 76, 1280])\n",
            "After LayerNorm: torch.Size([2, 76, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([76, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([76, 2, 1280])\n",
            "After adding attn_output: torch.Size([76, 2, 1280])\n",
            "After permute back: torch.Size([2, 76, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 76, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 76, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 76, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 76, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 76, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 77, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 77, 1280])\n",
            "After LayerNorm: torch.Size([2, 77, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([77, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([77, 2, 1280])\n",
            "After adding attn_output: torch.Size([77, 2, 1280])\n",
            "After permute back: torch.Size([2, 77, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 77, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 77, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 77, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 77, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 77, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 77, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 77, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 77, 1280])\n",
            "After LayerNorm: torch.Size([2, 77, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([77, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([77, 2, 1280])\n",
            "After adding attn_output: torch.Size([77, 2, 1280])\n",
            "After permute back: torch.Size([2, 77, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 77, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 77, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 77, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 77, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 77, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 78, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 78, 1280])\n",
            "After LayerNorm: torch.Size([2, 78, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([78, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([78, 2, 1280])\n",
            "After adding attn_output: torch.Size([78, 2, 1280])\n",
            "After permute back: torch.Size([2, 78, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 78, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 78, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 78, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 78, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 78, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 78, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 78, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 78, 1280])\n",
            "After LayerNorm: torch.Size([2, 78, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([78, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([78, 2, 1280])\n",
            "After adding attn_output: torch.Size([78, 2, 1280])\n",
            "After permute back: torch.Size([2, 78, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 78, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 78, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 78, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 78, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 78, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 79, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 79, 1280])\n",
            "After LayerNorm: torch.Size([2, 79, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([79, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([79, 2, 1280])\n",
            "After adding attn_output: torch.Size([79, 2, 1280])\n",
            "After permute back: torch.Size([2, 79, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 79, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 79, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 79, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 79, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 79, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 79, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 79, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 79, 1280])\n",
            "After LayerNorm: torch.Size([2, 79, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([79, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([79, 2, 1280])\n",
            "After adding attn_output: torch.Size([79, 2, 1280])\n",
            "After permute back: torch.Size([2, 79, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 79, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 79, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 79, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 79, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 79, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 80, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 80, 1280])\n",
            "After LayerNorm: torch.Size([2, 80, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([80, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([80, 2, 1280])\n",
            "After adding attn_output: torch.Size([80, 2, 1280])\n",
            "After permute back: torch.Size([2, 80, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 80, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 80, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 80, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 80, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 80, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 80, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 80, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 80, 1280])\n",
            "After LayerNorm: torch.Size([2, 80, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([80, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([80, 2, 1280])\n",
            "After adding attn_output: torch.Size([80, 2, 1280])\n",
            "After permute back: torch.Size([2, 80, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 80, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 80, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 80, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 80, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 80, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 81, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 81, 1280])\n",
            "After LayerNorm: torch.Size([2, 81, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([81, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([81, 2, 1280])\n",
            "After adding attn_output: torch.Size([81, 2, 1280])\n",
            "After permute back: torch.Size([2, 81, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 81, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 81, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 81, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 81, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 81, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 81, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 81, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 81, 1280])\n",
            "After LayerNorm: torch.Size([2, 81, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([81, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([81, 2, 1280])\n",
            "After adding attn_output: torch.Size([81, 2, 1280])\n",
            "After permute back: torch.Size([2, 81, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 81, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 81, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 81, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 81, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 81, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 82, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 82, 1280])\n",
            "After LayerNorm: torch.Size([2, 82, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([82, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([82, 2, 1280])\n",
            "After adding attn_output: torch.Size([82, 2, 1280])\n",
            "After permute back: torch.Size([2, 82, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 82, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 82, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 82, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 82, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 82, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 82, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 82, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 82, 1280])\n",
            "After LayerNorm: torch.Size([2, 82, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([82, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([82, 2, 1280])\n",
            "After adding attn_output: torch.Size([82, 2, 1280])\n",
            "After permute back: torch.Size([2, 82, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 82, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 82, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 82, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 82, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 82, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 83, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 83, 1280])\n",
            "After LayerNorm: torch.Size([2, 83, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([83, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([83, 2, 1280])\n",
            "After adding attn_output: torch.Size([83, 2, 1280])\n",
            "After permute back: torch.Size([2, 83, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 83, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 83, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 83, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 83, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 83, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 83, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 83, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 83, 1280])\n",
            "After LayerNorm: torch.Size([2, 83, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([83, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([83, 2, 1280])\n",
            "After adding attn_output: torch.Size([83, 2, 1280])\n",
            "After permute back: torch.Size([2, 83, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 83, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 83, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 83, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 83, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 83, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 84, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 84, 1280])\n",
            "After LayerNorm: torch.Size([2, 84, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([84, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([84, 2, 1280])\n",
            "After adding attn_output: torch.Size([84, 2, 1280])\n",
            "After permute back: torch.Size([2, 84, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 84, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 84, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 84, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 84, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 84, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 84, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 84, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 84, 1280])\n",
            "After LayerNorm: torch.Size([2, 84, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([84, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([84, 2, 1280])\n",
            "After adding attn_output: torch.Size([84, 2, 1280])\n",
            "After permute back: torch.Size([2, 84, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 84, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 84, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 84, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 84, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 84, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 85, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 85, 1280])\n",
            "After LayerNorm: torch.Size([2, 85, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([85, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([85, 2, 1280])\n",
            "After adding attn_output: torch.Size([85, 2, 1280])\n",
            "After permute back: torch.Size([2, 85, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 85, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 85, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 85, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 85, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 85, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 85, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 85, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 85, 1280])\n",
            "After LayerNorm: torch.Size([2, 85, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([85, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([85, 2, 1280])\n",
            "After adding attn_output: torch.Size([85, 2, 1280])\n",
            "After permute back: torch.Size([2, 85, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 85, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 85, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 85, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 85, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 85, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 86, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 86, 1280])\n",
            "After LayerNorm: torch.Size([2, 86, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([86, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([86, 2, 1280])\n",
            "After adding attn_output: torch.Size([86, 2, 1280])\n",
            "After permute back: torch.Size([2, 86, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 86, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 86, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 86, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 86, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 86, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 86, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 86, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 86, 1280])\n",
            "After LayerNorm: torch.Size([2, 86, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([86, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([86, 2, 1280])\n",
            "After adding attn_output: torch.Size([86, 2, 1280])\n",
            "After permute back: torch.Size([2, 86, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 86, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 86, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 86, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 86, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 86, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 87, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 87, 1280])\n",
            "After LayerNorm: torch.Size([2, 87, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([87, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([87, 2, 1280])\n",
            "After adding attn_output: torch.Size([87, 2, 1280])\n",
            "After permute back: torch.Size([2, 87, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 87, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 87, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 87, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 87, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 87, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 87, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 87, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 87, 1280])\n",
            "After LayerNorm: torch.Size([2, 87, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([87, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([87, 2, 1280])\n",
            "After adding attn_output: torch.Size([87, 2, 1280])\n",
            "After permute back: torch.Size([2, 87, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 87, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 87, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 87, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 87, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 87, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 88, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 88, 1280])\n",
            "After LayerNorm: torch.Size([2, 88, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([88, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([88, 2, 1280])\n",
            "After adding attn_output: torch.Size([88, 2, 1280])\n",
            "After permute back: torch.Size([2, 88, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 88, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 88, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 88, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 88, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 88, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 88, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 88, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 88, 1280])\n",
            "After LayerNorm: torch.Size([2, 88, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([88, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([88, 2, 1280])\n",
            "After adding attn_output: torch.Size([88, 2, 1280])\n",
            "After permute back: torch.Size([2, 88, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 88, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 88, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 88, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 88, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 88, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 89, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 89, 1280])\n",
            "After LayerNorm: torch.Size([2, 89, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([89, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([89, 2, 1280])\n",
            "After adding attn_output: torch.Size([89, 2, 1280])\n",
            "After permute back: torch.Size([2, 89, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 89, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 89, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 89, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 89, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 89, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 89, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 89, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 89, 1280])\n",
            "After LayerNorm: torch.Size([2, 89, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([89, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([89, 2, 1280])\n",
            "After adding attn_output: torch.Size([89, 2, 1280])\n",
            "After permute back: torch.Size([2, 89, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 89, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 89, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 89, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 89, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 89, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 90, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 90, 1280])\n",
            "After LayerNorm: torch.Size([2, 90, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([90, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([90, 2, 1280])\n",
            "After adding attn_output: torch.Size([90, 2, 1280])\n",
            "After permute back: torch.Size([2, 90, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 90, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 90, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 90, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 90, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 90, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 90, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 90, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 90, 1280])\n",
            "After LayerNorm: torch.Size([2, 90, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([90, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([90, 2, 1280])\n",
            "After adding attn_output: torch.Size([90, 2, 1280])\n",
            "After permute back: torch.Size([2, 90, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 90, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 90, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 90, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 90, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 90, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 91, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 91, 1280])\n",
            "After LayerNorm: torch.Size([2, 91, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([91, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([91, 2, 1280])\n",
            "After adding attn_output: torch.Size([91, 2, 1280])\n",
            "After permute back: torch.Size([2, 91, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 91, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 91, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 91, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 91, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 91, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 91, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 91, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 91, 1280])\n",
            "After LayerNorm: torch.Size([2, 91, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([91, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([91, 2, 1280])\n",
            "After adding attn_output: torch.Size([91, 2, 1280])\n",
            "After permute back: torch.Size([2, 91, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 91, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 91, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 91, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 91, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 91, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 92, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 92, 1280])\n",
            "After LayerNorm: torch.Size([2, 92, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([92, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([92, 2, 1280])\n",
            "After adding attn_output: torch.Size([92, 2, 1280])\n",
            "After permute back: torch.Size([2, 92, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 92, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 92, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 92, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 92, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 92, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 92, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 92, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 92, 1280])\n",
            "After LayerNorm: torch.Size([2, 92, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([92, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([92, 2, 1280])\n",
            "After adding attn_output: torch.Size([92, 2, 1280])\n",
            "After permute back: torch.Size([2, 92, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 92, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 92, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 92, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 92, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 92, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 93, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 93, 1280])\n",
            "After LayerNorm: torch.Size([2, 93, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([93, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([93, 2, 1280])\n",
            "After adding attn_output: torch.Size([93, 2, 1280])\n",
            "After permute back: torch.Size([2, 93, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 93, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 93, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 93, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 93, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 93, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 93, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 93, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 93, 1280])\n",
            "After LayerNorm: torch.Size([2, 93, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([93, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([93, 2, 1280])\n",
            "After adding attn_output: torch.Size([93, 2, 1280])\n",
            "After permute back: torch.Size([2, 93, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 93, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 93, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 93, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 93, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 93, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 94, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 94, 1280])\n",
            "After LayerNorm: torch.Size([2, 94, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([94, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([94, 2, 1280])\n",
            "After adding attn_output: torch.Size([94, 2, 1280])\n",
            "After permute back: torch.Size([2, 94, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 94, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 94, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 94, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 94, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 94, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 94, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 94, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 94, 1280])\n",
            "After LayerNorm: torch.Size([2, 94, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([94, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([94, 2, 1280])\n",
            "After adding attn_output: torch.Size([94, 2, 1280])\n",
            "After permute back: torch.Size([2, 94, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 94, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 94, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 94, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 94, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 94, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 95, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 95, 1280])\n",
            "After LayerNorm: torch.Size([2, 95, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([95, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([95, 2, 1280])\n",
            "After adding attn_output: torch.Size([95, 2, 1280])\n",
            "After permute back: torch.Size([2, 95, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 95, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 95, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 95, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 95, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 95, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 95, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 95, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 95, 1280])\n",
            "After LayerNorm: torch.Size([2, 95, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([95, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([95, 2, 1280])\n",
            "After adding attn_output: torch.Size([95, 2, 1280])\n",
            "After permute back: torch.Size([2, 95, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 95, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 95, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 95, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 95, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 95, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 96, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 96, 1280])\n",
            "After LayerNorm: torch.Size([2, 96, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([96, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([96, 2, 1280])\n",
            "After adding attn_output: torch.Size([96, 2, 1280])\n",
            "After permute back: torch.Size([2, 96, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 96, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 96, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 96, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 96, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 96, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 96, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 96, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 96, 1280])\n",
            "After LayerNorm: torch.Size([2, 96, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([96, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([96, 2, 1280])\n",
            "After adding attn_output: torch.Size([96, 2, 1280])\n",
            "After permute back: torch.Size([2, 96, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 96, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 96, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 96, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 96, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 96, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 97, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 97, 1280])\n",
            "After LayerNorm: torch.Size([2, 97, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([97, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([97, 2, 1280])\n",
            "After adding attn_output: torch.Size([97, 2, 1280])\n",
            "After permute back: torch.Size([2, 97, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 97, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 97, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 97, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 97, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 97, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 97, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 97, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 97, 1280])\n",
            "After LayerNorm: torch.Size([2, 97, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([97, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([97, 2, 1280])\n",
            "After adding attn_output: torch.Size([97, 2, 1280])\n",
            "After permute back: torch.Size([2, 97, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 97, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 97, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 97, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 97, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 97, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 98, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 98, 1280])\n",
            "After LayerNorm: torch.Size([2, 98, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([98, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([98, 2, 1280])\n",
            "After adding attn_output: torch.Size([98, 2, 1280])\n",
            "After permute back: torch.Size([2, 98, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 98, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 98, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 98, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 98, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 98, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 98, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 98, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 98, 1280])\n",
            "After LayerNorm: torch.Size([2, 98, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([98, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([98, 2, 1280])\n",
            "After adding attn_output: torch.Size([98, 2, 1280])\n",
            "After permute back: torch.Size([2, 98, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 98, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 98, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 98, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 98, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 98, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 99, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 99, 1280])\n",
            "After LayerNorm: torch.Size([2, 99, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([99, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([99, 2, 1280])\n",
            "After adding attn_output: torch.Size([99, 2, 1280])\n",
            "After permute back: torch.Size([2, 99, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 99, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 99, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 99, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 99, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 99, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 99, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 99, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 99, 1280])\n",
            "After LayerNorm: torch.Size([2, 99, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([99, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([99, 2, 1280])\n",
            "After adding attn_output: torch.Size([99, 2, 1280])\n",
            "After permute back: torch.Size([2, 99, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 99, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 99, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 99, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 99, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 99, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 100, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 100, 1280])\n",
            "After LayerNorm: torch.Size([2, 100, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([100, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([100, 2, 1280])\n",
            "After adding attn_output: torch.Size([100, 2, 1280])\n",
            "After permute back: torch.Size([2, 100, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 100, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 100, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 100, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 100, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 100, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 100, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 100, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 100, 1280])\n",
            "After LayerNorm: torch.Size([2, 100, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([100, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([100, 2, 1280])\n",
            "After adding attn_output: torch.Size([100, 2, 1280])\n",
            "After permute back: torch.Size([2, 100, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 100, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 100, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 100, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 100, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 100, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 101, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 101, 1280])\n",
            "After LayerNorm: torch.Size([2, 101, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([101, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([101, 2, 1280])\n",
            "After adding attn_output: torch.Size([101, 2, 1280])\n",
            "After permute back: torch.Size([2, 101, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 101, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 101, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 101, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 101, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 101, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 101, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 101, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 101, 1280])\n",
            "After LayerNorm: torch.Size([2, 101, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([101, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([101, 2, 1280])\n",
            "After adding attn_output: torch.Size([101, 2, 1280])\n",
            "After permute back: torch.Size([2, 101, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 101, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 101, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 101, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 101, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 101, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 102, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 102, 1280])\n",
            "After LayerNorm: torch.Size([2, 102, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([102, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([102, 2, 1280])\n",
            "After adding attn_output: torch.Size([102, 2, 1280])\n",
            "After permute back: torch.Size([2, 102, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 102, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 102, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 102, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 102, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 102, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 102, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 102, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 102, 1280])\n",
            "After LayerNorm: torch.Size([2, 102, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([102, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([102, 2, 1280])\n",
            "After adding attn_output: torch.Size([102, 2, 1280])\n",
            "After permute back: torch.Size([2, 102, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 102, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 102, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 102, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 102, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 102, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 103, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 103, 1280])\n",
            "After LayerNorm: torch.Size([2, 103, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([103, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([103, 2, 1280])\n",
            "After adding attn_output: torch.Size([103, 2, 1280])\n",
            "After permute back: torch.Size([2, 103, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 103, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 103, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 103, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 103, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 103, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 103, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 103, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 103, 1280])\n",
            "After LayerNorm: torch.Size([2, 103, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([103, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([103, 2, 1280])\n",
            "After adding attn_output: torch.Size([103, 2, 1280])\n",
            "After permute back: torch.Size([2, 103, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 103, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 103, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 103, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 103, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 103, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 104, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 104, 1280])\n",
            "After LayerNorm: torch.Size([2, 104, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([104, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([104, 2, 1280])\n",
            "After adding attn_output: torch.Size([104, 2, 1280])\n",
            "After permute back: torch.Size([2, 104, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 104, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 104, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 104, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 104, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 104, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 104, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 104, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 104, 1280])\n",
            "After LayerNorm: torch.Size([2, 104, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([104, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([104, 2, 1280])\n",
            "After adding attn_output: torch.Size([104, 2, 1280])\n",
            "After permute back: torch.Size([2, 104, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 104, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 104, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 104, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 104, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 104, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 105, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 105, 1280])\n",
            "After LayerNorm: torch.Size([2, 105, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([105, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([105, 2, 1280])\n",
            "After adding attn_output: torch.Size([105, 2, 1280])\n",
            "After permute back: torch.Size([2, 105, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 105, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 105, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 105, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 105, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 105, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 105, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 105, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 105, 1280])\n",
            "After LayerNorm: torch.Size([2, 105, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([105, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([105, 2, 1280])\n",
            "After adding attn_output: torch.Size([105, 2, 1280])\n",
            "After permute back: torch.Size([2, 105, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 105, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 105, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 105, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 105, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 105, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 106, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 106, 1280])\n",
            "After LayerNorm: torch.Size([2, 106, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([106, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([106, 2, 1280])\n",
            "After adding attn_output: torch.Size([106, 2, 1280])\n",
            "After permute back: torch.Size([2, 106, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 106, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 106, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 106, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 106, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 106, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 106, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 106, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 106, 1280])\n",
            "After LayerNorm: torch.Size([2, 106, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([106, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([106, 2, 1280])\n",
            "After adding attn_output: torch.Size([106, 2, 1280])\n",
            "After permute back: torch.Size([2, 106, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 106, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 106, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 106, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 106, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 106, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 107, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 107, 1280])\n",
            "After LayerNorm: torch.Size([2, 107, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([107, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([107, 2, 1280])\n",
            "After adding attn_output: torch.Size([107, 2, 1280])\n",
            "After permute back: torch.Size([2, 107, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 107, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 107, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 107, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 107, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 107, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 107, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 107, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 107, 1280])\n",
            "After LayerNorm: torch.Size([2, 107, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([107, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([107, 2, 1280])\n",
            "After adding attn_output: torch.Size([107, 2, 1280])\n",
            "After permute back: torch.Size([2, 107, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 107, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 107, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 107, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 107, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 107, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 108, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 108, 1280])\n",
            "After LayerNorm: torch.Size([2, 108, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([108, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([108, 2, 1280])\n",
            "After adding attn_output: torch.Size([108, 2, 1280])\n",
            "After permute back: torch.Size([2, 108, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 108, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 108, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 108, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 108, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 108, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 108, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 108, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 108, 1280])\n",
            "After LayerNorm: torch.Size([2, 108, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([108, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([108, 2, 1280])\n",
            "After adding attn_output: torch.Size([108, 2, 1280])\n",
            "After permute back: torch.Size([2, 108, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 108, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 108, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 108, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 108, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 108, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 109, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 109, 1280])\n",
            "After LayerNorm: torch.Size([2, 109, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([109, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([109, 2, 1280])\n",
            "After adding attn_output: torch.Size([109, 2, 1280])\n",
            "After permute back: torch.Size([2, 109, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 109, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 109, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 109, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 109, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 109, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 109, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 109, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 109, 1280])\n",
            "After LayerNorm: torch.Size([2, 109, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([109, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([109, 2, 1280])\n",
            "After adding attn_output: torch.Size([109, 2, 1280])\n",
            "After permute back: torch.Size([2, 109, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 109, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 109, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 109, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 109, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 109, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 110, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 110, 1280])\n",
            "After LayerNorm: torch.Size([2, 110, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([110, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([110, 2, 1280])\n",
            "After adding attn_output: torch.Size([110, 2, 1280])\n",
            "After permute back: torch.Size([2, 110, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 110, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 110, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 110, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 110, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 110, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 110, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 110, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 110, 1280])\n",
            "After LayerNorm: torch.Size([2, 110, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([110, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([110, 2, 1280])\n",
            "After adding attn_output: torch.Size([110, 2, 1280])\n",
            "After permute back: torch.Size([2, 110, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 110, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 110, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 110, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 110, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 110, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 111, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 111, 1280])\n",
            "After LayerNorm: torch.Size([2, 111, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([111, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([111, 2, 1280])\n",
            "After adding attn_output: torch.Size([111, 2, 1280])\n",
            "After permute back: torch.Size([2, 111, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 111, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 111, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 111, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 111, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 111, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 111, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 111, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 111, 1280])\n",
            "After LayerNorm: torch.Size([2, 111, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([111, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([111, 2, 1280])\n",
            "After adding attn_output: torch.Size([111, 2, 1280])\n",
            "After permute back: torch.Size([2, 111, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 111, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 111, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 111, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 111, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 111, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 112, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 112, 1280])\n",
            "After LayerNorm: torch.Size([2, 112, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([112, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([112, 2, 1280])\n",
            "After adding attn_output: torch.Size([112, 2, 1280])\n",
            "After permute back: torch.Size([2, 112, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 112, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 112, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 112, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 112, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 112, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 112, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 112, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 112, 1280])\n",
            "After LayerNorm: torch.Size([2, 112, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([112, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([112, 2, 1280])\n",
            "After adding attn_output: torch.Size([112, 2, 1280])\n",
            "After permute back: torch.Size([2, 112, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 112, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 112, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 112, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 112, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 112, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 113, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 113, 1280])\n",
            "After LayerNorm: torch.Size([2, 113, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([113, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([113, 2, 1280])\n",
            "After adding attn_output: torch.Size([113, 2, 1280])\n",
            "After permute back: torch.Size([2, 113, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 113, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 113, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 113, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 113, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 113, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 113, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 113, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 113, 1280])\n",
            "After LayerNorm: torch.Size([2, 113, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([113, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([113, 2, 1280])\n",
            "After adding attn_output: torch.Size([113, 2, 1280])\n",
            "After permute back: torch.Size([2, 113, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 113, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 113, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 113, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 113, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 113, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 114, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 114, 1280])\n",
            "After LayerNorm: torch.Size([2, 114, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([114, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([114, 2, 1280])\n",
            "After adding attn_output: torch.Size([114, 2, 1280])\n",
            "After permute back: torch.Size([2, 114, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 114, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 114, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 114, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 114, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 114, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 114, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 114, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 114, 1280])\n",
            "After LayerNorm: torch.Size([2, 114, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([114, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([114, 2, 1280])\n",
            "After adding attn_output: torch.Size([114, 2, 1280])\n",
            "After permute back: torch.Size([2, 114, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 114, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 114, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 114, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 114, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 114, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 115, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 115, 1280])\n",
            "After LayerNorm: torch.Size([2, 115, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([115, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([115, 2, 1280])\n",
            "After adding attn_output: torch.Size([115, 2, 1280])\n",
            "After permute back: torch.Size([2, 115, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 115, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 115, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 115, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 115, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 115, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 115, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 115, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 115, 1280])\n",
            "After LayerNorm: torch.Size([2, 115, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([115, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([115, 2, 1280])\n",
            "After adding attn_output: torch.Size([115, 2, 1280])\n",
            "After permute back: torch.Size([2, 115, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 115, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 115, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 115, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 115, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 115, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 116, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 116, 1280])\n",
            "After LayerNorm: torch.Size([2, 116, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([116, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([116, 2, 1280])\n",
            "After adding attn_output: torch.Size([116, 2, 1280])\n",
            "After permute back: torch.Size([2, 116, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 116, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 116, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 116, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 116, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 116, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 116, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 116, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 116, 1280])\n",
            "After LayerNorm: torch.Size([2, 116, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([116, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([116, 2, 1280])\n",
            "After adding attn_output: torch.Size([116, 2, 1280])\n",
            "After permute back: torch.Size([2, 116, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 116, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 116, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 116, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 116, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 116, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 117, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 117, 1280])\n",
            "After LayerNorm: torch.Size([2, 117, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([117, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([117, 2, 1280])\n",
            "After adding attn_output: torch.Size([117, 2, 1280])\n",
            "After permute back: torch.Size([2, 117, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 117, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 117, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 117, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 117, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 117, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 117, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 117, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 117, 1280])\n",
            "After LayerNorm: torch.Size([2, 117, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([117, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([117, 2, 1280])\n",
            "After adding attn_output: torch.Size([117, 2, 1280])\n",
            "After permute back: torch.Size([2, 117, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 117, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 117, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 117, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 117, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 117, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 118, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 118, 1280])\n",
            "After LayerNorm: torch.Size([2, 118, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([118, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([118, 2, 1280])\n",
            "After adding attn_output: torch.Size([118, 2, 1280])\n",
            "After permute back: torch.Size([2, 118, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 118, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 118, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 118, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 118, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 118, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 118, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 118, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 118, 1280])\n",
            "After LayerNorm: torch.Size([2, 118, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([118, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([118, 2, 1280])\n",
            "After adding attn_output: torch.Size([118, 2, 1280])\n",
            "After permute back: torch.Size([2, 118, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 118, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 118, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 118, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 118, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 118, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 119, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 119, 1280])\n",
            "After LayerNorm: torch.Size([2, 119, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([119, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([119, 2, 1280])\n",
            "After adding attn_output: torch.Size([119, 2, 1280])\n",
            "After permute back: torch.Size([2, 119, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 119, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 119, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 119, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 119, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 119, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 119, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 119, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 119, 1280])\n",
            "After LayerNorm: torch.Size([2, 119, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([119, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([119, 2, 1280])\n",
            "After adding attn_output: torch.Size([119, 2, 1280])\n",
            "After permute back: torch.Size([2, 119, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 119, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 119, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 119, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 119, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 119, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 120, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 120, 1280])\n",
            "After LayerNorm: torch.Size([2, 120, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([120, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([120, 2, 1280])\n",
            "After adding attn_output: torch.Size([120, 2, 1280])\n",
            "After permute back: torch.Size([2, 120, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 120, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 120, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 120, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 120, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 120, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 120, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 120, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 120, 1280])\n",
            "After LayerNorm: torch.Size([2, 120, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([120, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([120, 2, 1280])\n",
            "After adding attn_output: torch.Size([120, 2, 1280])\n",
            "After permute back: torch.Size([2, 120, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 120, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 120, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 120, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 120, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 120, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 121, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 121, 1280])\n",
            "After LayerNorm: torch.Size([2, 121, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([121, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([121, 2, 1280])\n",
            "After adding attn_output: torch.Size([121, 2, 1280])\n",
            "After permute back: torch.Size([2, 121, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 121, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 121, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 121, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 121, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 121, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 121, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 121, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 121, 1280])\n",
            "After LayerNorm: torch.Size([2, 121, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([121, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([121, 2, 1280])\n",
            "After adding attn_output: torch.Size([121, 2, 1280])\n",
            "After permute back: torch.Size([2, 121, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 121, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 121, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 121, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 121, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 121, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 122, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 122, 1280])\n",
            "After LayerNorm: torch.Size([2, 122, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([122, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([122, 2, 1280])\n",
            "After adding attn_output: torch.Size([122, 2, 1280])\n",
            "After permute back: torch.Size([2, 122, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 122, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 122, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 122, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 122, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 122, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 122, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 122, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 122, 1280])\n",
            "After LayerNorm: torch.Size([2, 122, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([122, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([122, 2, 1280])\n",
            "After adding attn_output: torch.Size([122, 2, 1280])\n",
            "After permute back: torch.Size([2, 122, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 122, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 122, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 122, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 122, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 122, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 123, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 123, 1280])\n",
            "After LayerNorm: torch.Size([2, 123, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([123, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([123, 2, 1280])\n",
            "After adding attn_output: torch.Size([123, 2, 1280])\n",
            "After permute back: torch.Size([2, 123, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 123, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 123, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 123, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 123, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 123, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 123, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 123, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 123, 1280])\n",
            "After LayerNorm: torch.Size([2, 123, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([123, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([123, 2, 1280])\n",
            "After adding attn_output: torch.Size([123, 2, 1280])\n",
            "After permute back: torch.Size([2, 123, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 123, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 123, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 123, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 123, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 123, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 124, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 124, 1280])\n",
            "After LayerNorm: torch.Size([2, 124, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([124, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([124, 2, 1280])\n",
            "After adding attn_output: torch.Size([124, 2, 1280])\n",
            "After permute back: torch.Size([2, 124, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 124, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 124, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 124, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 124, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 124, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 124, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 124, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 124, 1280])\n",
            "After LayerNorm: torch.Size([2, 124, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([124, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([124, 2, 1280])\n",
            "After adding attn_output: torch.Size([124, 2, 1280])\n",
            "After permute back: torch.Size([2, 124, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 124, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 124, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 124, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 124, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 124, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 125, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 125, 1280])\n",
            "After LayerNorm: torch.Size([2, 125, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([125, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([125, 2, 1280])\n",
            "After adding attn_output: torch.Size([125, 2, 1280])\n",
            "After permute back: torch.Size([2, 125, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 125, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 125, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 125, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 125, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 125, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 125, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 125, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 125, 1280])\n",
            "After LayerNorm: torch.Size([2, 125, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([125, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([125, 2, 1280])\n",
            "After adding attn_output: torch.Size([125, 2, 1280])\n",
            "After permute back: torch.Size([2, 125, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 125, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 125, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 125, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 125, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 125, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 126, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 126, 1280])\n",
            "After LayerNorm: torch.Size([2, 126, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([126, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([126, 2, 1280])\n",
            "After adding attn_output: torch.Size([126, 2, 1280])\n",
            "After permute back: torch.Size([2, 126, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 126, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 126, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 126, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 126, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 126, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 126, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 126, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 126, 1280])\n",
            "After LayerNorm: torch.Size([2, 126, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([126, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([126, 2, 1280])\n",
            "After adding attn_output: torch.Size([126, 2, 1280])\n",
            "After permute back: torch.Size([2, 126, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 126, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 126, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 126, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 126, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 126, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 127, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 127, 1280])\n",
            "After LayerNorm: torch.Size([2, 127, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([127, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([127, 2, 1280])\n",
            "After adding attn_output: torch.Size([127, 2, 1280])\n",
            "After permute back: torch.Size([2, 127, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 127, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 127, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 127, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 127, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 127, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 127, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 127, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 127, 1280])\n",
            "After LayerNorm: torch.Size([2, 127, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([127, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([127, 2, 1280])\n",
            "After adding attn_output: torch.Size([127, 2, 1280])\n",
            "After permute back: torch.Size([2, 127, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 127, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 127, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 127, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 127, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 127, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 128, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 128, 1280])\n",
            "After LayerNorm: torch.Size([2, 128, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([128, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([128, 2, 1280])\n",
            "After adding attn_output: torch.Size([128, 2, 1280])\n",
            "After permute back: torch.Size([2, 128, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 128, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 128, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 128, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 128, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 128, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 128, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 128, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 128, 1280])\n",
            "After LayerNorm: torch.Size([2, 128, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([128, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([128, 2, 1280])\n",
            "After adding attn_output: torch.Size([128, 2, 1280])\n",
            "After permute back: torch.Size([2, 128, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 128, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 128, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 128, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 128, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 128, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 129, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 129, 1280])\n",
            "After LayerNorm: torch.Size([2, 129, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([129, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([129, 2, 1280])\n",
            "After adding attn_output: torch.Size([129, 2, 1280])\n",
            "After permute back: torch.Size([2, 129, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 129, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 129, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 129, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 129, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 129, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 129, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 129, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 129, 1280])\n",
            "After LayerNorm: torch.Size([2, 129, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([129, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([129, 2, 1280])\n",
            "After adding attn_output: torch.Size([129, 2, 1280])\n",
            "After permute back: torch.Size([2, 129, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 129, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 129, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 129, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 129, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 129, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 130, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 130, 1280])\n",
            "After LayerNorm: torch.Size([2, 130, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([130, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([130, 2, 1280])\n",
            "After adding attn_output: torch.Size([130, 2, 1280])\n",
            "After permute back: torch.Size([2, 130, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 130, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 130, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 130, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 130, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 130, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 130, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 130, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 130, 1280])\n",
            "After LayerNorm: torch.Size([2, 130, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([130, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([130, 2, 1280])\n",
            "After adding attn_output: torch.Size([130, 2, 1280])\n",
            "After permute back: torch.Size([2, 130, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 130, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 130, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 130, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 130, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 130, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 131, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 131, 1280])\n",
            "After LayerNorm: torch.Size([2, 131, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([131, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([131, 2, 1280])\n",
            "After adding attn_output: torch.Size([131, 2, 1280])\n",
            "After permute back: torch.Size([2, 131, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 131, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 131, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 131, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 131, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 131, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 131, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 131, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 131, 1280])\n",
            "After LayerNorm: torch.Size([2, 131, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([131, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([131, 2, 1280])\n",
            "After adding attn_output: torch.Size([131, 2, 1280])\n",
            "After permute back: torch.Size([2, 131, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 131, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 131, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 131, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 131, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 131, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 132, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 132, 1280])\n",
            "After LayerNorm: torch.Size([2, 132, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([132, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([132, 2, 1280])\n",
            "After adding attn_output: torch.Size([132, 2, 1280])\n",
            "After permute back: torch.Size([2, 132, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 132, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 132, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 132, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 132, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 132, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 132, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 132, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 132, 1280])\n",
            "After LayerNorm: torch.Size([2, 132, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([132, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([132, 2, 1280])\n",
            "After adding attn_output: torch.Size([132, 2, 1280])\n",
            "After permute back: torch.Size([2, 132, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 132, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 132, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 132, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 132, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 132, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 133, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 133, 1280])\n",
            "After LayerNorm: torch.Size([2, 133, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([133, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([133, 2, 1280])\n",
            "After adding attn_output: torch.Size([133, 2, 1280])\n",
            "After permute back: torch.Size([2, 133, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 133, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 133, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 133, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 133, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 133, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 133, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 133, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 133, 1280])\n",
            "After LayerNorm: torch.Size([2, 133, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([133, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([133, 2, 1280])\n",
            "After adding attn_output: torch.Size([133, 2, 1280])\n",
            "After permute back: torch.Size([2, 133, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 133, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 133, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 133, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 133, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 133, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 134, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 134, 1280])\n",
            "After LayerNorm: torch.Size([2, 134, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([134, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([134, 2, 1280])\n",
            "After adding attn_output: torch.Size([134, 2, 1280])\n",
            "After permute back: torch.Size([2, 134, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 134, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 134, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 134, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 134, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 134, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 134, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 134, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 134, 1280])\n",
            "After LayerNorm: torch.Size([2, 134, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([134, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([134, 2, 1280])\n",
            "After adding attn_output: torch.Size([134, 2, 1280])\n",
            "After permute back: torch.Size([2, 134, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 134, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 134, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 134, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 134, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 134, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 135, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 135, 1280])\n",
            "After LayerNorm: torch.Size([2, 135, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([135, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([135, 2, 1280])\n",
            "After adding attn_output: torch.Size([135, 2, 1280])\n",
            "After permute back: torch.Size([2, 135, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 135, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 135, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 135, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 135, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 135, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 135, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 135, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 135, 1280])\n",
            "After LayerNorm: torch.Size([2, 135, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([135, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([135, 2, 1280])\n",
            "After adding attn_output: torch.Size([135, 2, 1280])\n",
            "After permute back: torch.Size([2, 135, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 135, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 135, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 135, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 135, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 135, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 136, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 136, 1280])\n",
            "After LayerNorm: torch.Size([2, 136, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([136, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([136, 2, 1280])\n",
            "After adding attn_output: torch.Size([136, 2, 1280])\n",
            "After permute back: torch.Size([2, 136, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 136, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 136, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 136, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 136, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 136, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 136, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 136, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 136, 1280])\n",
            "After LayerNorm: torch.Size([2, 136, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([136, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([136, 2, 1280])\n",
            "After adding attn_output: torch.Size([136, 2, 1280])\n",
            "After permute back: torch.Size([2, 136, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 136, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 136, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 136, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 136, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 136, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 137, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 137, 1280])\n",
            "After LayerNorm: torch.Size([2, 137, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([137, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([137, 2, 1280])\n",
            "After adding attn_output: torch.Size([137, 2, 1280])\n",
            "After permute back: torch.Size([2, 137, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 137, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 137, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 137, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 137, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 137, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 137, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 137, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 137, 1280])\n",
            "After LayerNorm: torch.Size([2, 137, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([137, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([137, 2, 1280])\n",
            "After adding attn_output: torch.Size([137, 2, 1280])\n",
            "After permute back: torch.Size([2, 137, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 137, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 137, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 137, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 137, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 137, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 138, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 138, 1280])\n",
            "After LayerNorm: torch.Size([2, 138, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([138, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([138, 2, 1280])\n",
            "After adding attn_output: torch.Size([138, 2, 1280])\n",
            "After permute back: torch.Size([2, 138, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 138, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 138, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 138, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 138, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 138, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 138, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 138, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 138, 1280])\n",
            "After LayerNorm: torch.Size([2, 138, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([138, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([138, 2, 1280])\n",
            "After adding attn_output: torch.Size([138, 2, 1280])\n",
            "After permute back: torch.Size([2, 138, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 138, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 138, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 138, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 138, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 138, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 139, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 139, 1280])\n",
            "After LayerNorm: torch.Size([2, 139, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([139, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([139, 2, 1280])\n",
            "After adding attn_output: torch.Size([139, 2, 1280])\n",
            "After permute back: torch.Size([2, 139, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 139, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 139, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 139, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 139, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 139, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 139, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 139, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 139, 1280])\n",
            "After LayerNorm: torch.Size([2, 139, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([139, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([139, 2, 1280])\n",
            "After adding attn_output: torch.Size([139, 2, 1280])\n",
            "After permute back: torch.Size([2, 139, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 139, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 139, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 139, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 139, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 139, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 140, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 140, 1280])\n",
            "After LayerNorm: torch.Size([2, 140, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([140, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([140, 2, 1280])\n",
            "After adding attn_output: torch.Size([140, 2, 1280])\n",
            "After permute back: torch.Size([2, 140, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 140, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 140, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 140, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 140, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 140, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 140, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 140, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 140, 1280])\n",
            "After LayerNorm: torch.Size([2, 140, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([140, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([140, 2, 1280])\n",
            "After adding attn_output: torch.Size([140, 2, 1280])\n",
            "After permute back: torch.Size([2, 140, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 140, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 140, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 140, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 140, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 140, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 141, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 141, 1280])\n",
            "After LayerNorm: torch.Size([2, 141, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([141, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([141, 2, 1280])\n",
            "After adding attn_output: torch.Size([141, 2, 1280])\n",
            "After permute back: torch.Size([2, 141, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 141, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 141, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 141, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 141, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 141, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 141, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 141, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 141, 1280])\n",
            "After LayerNorm: torch.Size([2, 141, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([141, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([141, 2, 1280])\n",
            "After adding attn_output: torch.Size([141, 2, 1280])\n",
            "After permute back: torch.Size([2, 141, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 141, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 141, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 141, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 141, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 141, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 142, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 142, 1280])\n",
            "After LayerNorm: torch.Size([2, 142, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([142, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([142, 2, 1280])\n",
            "After adding attn_output: torch.Size([142, 2, 1280])\n",
            "After permute back: torch.Size([2, 142, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 142, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 142, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 142, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 142, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 142, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 142, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 142, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 142, 1280])\n",
            "After LayerNorm: torch.Size([2, 142, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([142, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([142, 2, 1280])\n",
            "After adding attn_output: torch.Size([142, 2, 1280])\n",
            "After permute back: torch.Size([2, 142, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 142, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 142, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 142, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 142, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 142, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 143, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 143, 1280])\n",
            "After LayerNorm: torch.Size([2, 143, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([143, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([143, 2, 1280])\n",
            "After adding attn_output: torch.Size([143, 2, 1280])\n",
            "After permute back: torch.Size([2, 143, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 143, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 143, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 143, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 143, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 143, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 143, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 143, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 143, 1280])\n",
            "After LayerNorm: torch.Size([2, 143, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([143, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([143, 2, 1280])\n",
            "After adding attn_output: torch.Size([143, 2, 1280])\n",
            "After permute back: torch.Size([2, 143, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 143, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 143, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 143, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 143, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 143, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 144, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 144, 1280])\n",
            "After LayerNorm: torch.Size([2, 144, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([144, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([144, 2, 1280])\n",
            "After adding attn_output: torch.Size([144, 2, 1280])\n",
            "After permute back: torch.Size([2, 144, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 144, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 144, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 144, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 144, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 144, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 144, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 144, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 144, 1280])\n",
            "After LayerNorm: torch.Size([2, 144, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([144, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([144, 2, 1280])\n",
            "After adding attn_output: torch.Size([144, 2, 1280])\n",
            "After permute back: torch.Size([2, 144, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 144, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 144, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 144, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 144, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 144, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 145, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 145, 1280])\n",
            "After LayerNorm: torch.Size([2, 145, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([145, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([145, 2, 1280])\n",
            "After adding attn_output: torch.Size([145, 2, 1280])\n",
            "After permute back: torch.Size([2, 145, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 145, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 145, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 145, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 145, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 145, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 145, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 145, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 145, 1280])\n",
            "After LayerNorm: torch.Size([2, 145, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([145, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([145, 2, 1280])\n",
            "After adding attn_output: torch.Size([145, 2, 1280])\n",
            "After permute back: torch.Size([2, 145, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 145, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 145, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 145, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 145, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 145, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 146, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 146, 1280])\n",
            "After LayerNorm: torch.Size([2, 146, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([146, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([146, 2, 1280])\n",
            "After adding attn_output: torch.Size([146, 2, 1280])\n",
            "After permute back: torch.Size([2, 146, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 146, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 146, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 146, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 146, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 146, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 146, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 146, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 146, 1280])\n",
            "After LayerNorm: torch.Size([2, 146, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([146, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([146, 2, 1280])\n",
            "After adding attn_output: torch.Size([146, 2, 1280])\n",
            "After permute back: torch.Size([2, 146, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 146, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 146, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 146, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 146, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 146, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 147, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 147, 1280])\n",
            "After LayerNorm: torch.Size([2, 147, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([147, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([147, 2, 1280])\n",
            "After adding attn_output: torch.Size([147, 2, 1280])\n",
            "After permute back: torch.Size([2, 147, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 147, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 147, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 147, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 147, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 147, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 147, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 147, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 147, 1280])\n",
            "After LayerNorm: torch.Size([2, 147, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([147, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([147, 2, 1280])\n",
            "After adding attn_output: torch.Size([147, 2, 1280])\n",
            "After permute back: torch.Size([2, 147, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 147, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 147, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 147, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 147, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 147, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 148, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 148, 1280])\n",
            "After LayerNorm: torch.Size([2, 148, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([148, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([148, 2, 1280])\n",
            "After adding attn_output: torch.Size([148, 2, 1280])\n",
            "After permute back: torch.Size([2, 148, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 148, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 148, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 148, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 148, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 148, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 148, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 148, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 148, 1280])\n",
            "After LayerNorm: torch.Size([2, 148, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([148, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([148, 2, 1280])\n",
            "After adding attn_output: torch.Size([148, 2, 1280])\n",
            "After permute back: torch.Size([2, 148, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 148, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 148, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 148, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 148, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 148, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 149, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 149, 1280])\n",
            "After LayerNorm: torch.Size([2, 149, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([149, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([149, 2, 1280])\n",
            "After adding attn_output: torch.Size([149, 2, 1280])\n",
            "After permute back: torch.Size([2, 149, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 149, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 149, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 149, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 149, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 149, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 149, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 149, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 149, 1280])\n",
            "After LayerNorm: torch.Size([2, 149, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([149, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([149, 2, 1280])\n",
            "After adding attn_output: torch.Size([149, 2, 1280])\n",
            "After permute back: torch.Size([2, 149, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 149, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 149, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 149, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 149, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 149, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 150, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 150, 1280])\n",
            "After LayerNorm: torch.Size([2, 150, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([150, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([150, 2, 1280])\n",
            "After adding attn_output: torch.Size([150, 2, 1280])\n",
            "After permute back: torch.Size([2, 150, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 150, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 150, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 150, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 150, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 150, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 150, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 150, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 150, 1280])\n",
            "After LayerNorm: torch.Size([2, 150, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([150, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([150, 2, 1280])\n",
            "After adding attn_output: torch.Size([150, 2, 1280])\n",
            "After permute back: torch.Size([2, 150, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 150, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 150, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 150, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 150, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 150, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 151, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 151, 1280])\n",
            "After LayerNorm: torch.Size([2, 151, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([151, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([151, 2, 1280])\n",
            "After adding attn_output: torch.Size([151, 2, 1280])\n",
            "After permute back: torch.Size([2, 151, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 151, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 151, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 151, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 151, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 151, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 151, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 151, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 151, 1280])\n",
            "After LayerNorm: torch.Size([2, 151, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([151, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([151, 2, 1280])\n",
            "After adding attn_output: torch.Size([151, 2, 1280])\n",
            "After permute back: torch.Size([2, 151, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 151, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 151, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 151, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 151, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 151, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 152, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 152, 1280])\n",
            "After LayerNorm: torch.Size([2, 152, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([152, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([152, 2, 1280])\n",
            "After adding attn_output: torch.Size([152, 2, 1280])\n",
            "After permute back: torch.Size([2, 152, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 152, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 152, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 152, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 152, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 152, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 152, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 152, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 152, 1280])\n",
            "After LayerNorm: torch.Size([2, 152, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([152, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([152, 2, 1280])\n",
            "After adding attn_output: torch.Size([152, 2, 1280])\n",
            "After permute back: torch.Size([2, 152, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 152, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 152, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 152, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 152, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 152, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 153, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 153, 1280])\n",
            "After LayerNorm: torch.Size([2, 153, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([153, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([153, 2, 1280])\n",
            "After adding attn_output: torch.Size([153, 2, 1280])\n",
            "After permute back: torch.Size([2, 153, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 153, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 153, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 153, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 153, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 153, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 153, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 153, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 153, 1280])\n",
            "After LayerNorm: torch.Size([2, 153, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([153, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([153, 2, 1280])\n",
            "After adding attn_output: torch.Size([153, 2, 1280])\n",
            "After permute back: torch.Size([2, 153, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 153, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 153, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 153, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 153, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 153, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 154, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 154, 1280])\n",
            "After LayerNorm: torch.Size([2, 154, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([154, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([154, 2, 1280])\n",
            "After adding attn_output: torch.Size([154, 2, 1280])\n",
            "After permute back: torch.Size([2, 154, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 154, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 154, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 154, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 154, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 154, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 154, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 154, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 154, 1280])\n",
            "After LayerNorm: torch.Size([2, 154, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([154, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([154, 2, 1280])\n",
            "After adding attn_output: torch.Size([154, 2, 1280])\n",
            "After permute back: torch.Size([2, 154, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 154, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 154, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 154, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 154, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 154, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 155, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 155, 1280])\n",
            "After LayerNorm: torch.Size([2, 155, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([155, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([155, 2, 1280])\n",
            "After adding attn_output: torch.Size([155, 2, 1280])\n",
            "After permute back: torch.Size([2, 155, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 155, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 155, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 155, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 155, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 155, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 155, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 155, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 155, 1280])\n",
            "After LayerNorm: torch.Size([2, 155, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([155, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([155, 2, 1280])\n",
            "After adding attn_output: torch.Size([155, 2, 1280])\n",
            "After permute back: torch.Size([2, 155, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 155, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 155, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 155, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 155, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 155, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 156, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 156, 1280])\n",
            "After LayerNorm: torch.Size([2, 156, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([156, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([156, 2, 1280])\n",
            "After adding attn_output: torch.Size([156, 2, 1280])\n",
            "After permute back: torch.Size([2, 156, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 156, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 156, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 156, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 156, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 156, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 156, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 156, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 156, 1280])\n",
            "After LayerNorm: torch.Size([2, 156, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([156, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([156, 2, 1280])\n",
            "After adding attn_output: torch.Size([156, 2, 1280])\n",
            "After permute back: torch.Size([2, 156, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 156, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 156, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 156, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 156, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 156, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 157, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 157, 1280])\n",
            "After LayerNorm: torch.Size([2, 157, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([157, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([157, 2, 1280])\n",
            "After adding attn_output: torch.Size([157, 2, 1280])\n",
            "After permute back: torch.Size([2, 157, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 157, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 157, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 157, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 157, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 157, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 157, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 157, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 157, 1280])\n",
            "After LayerNorm: torch.Size([2, 157, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([157, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([157, 2, 1280])\n",
            "After adding attn_output: torch.Size([157, 2, 1280])\n",
            "After permute back: torch.Size([2, 157, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 157, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 157, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 157, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 157, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 157, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 158, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 158, 1280])\n",
            "After LayerNorm: torch.Size([2, 158, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([158, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([158, 2, 1280])\n",
            "After adding attn_output: torch.Size([158, 2, 1280])\n",
            "After permute back: torch.Size([2, 158, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 158, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 158, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 158, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 158, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 158, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 158, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 158, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 158, 1280])\n",
            "After LayerNorm: torch.Size([2, 158, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([158, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([158, 2, 1280])\n",
            "After adding attn_output: torch.Size([158, 2, 1280])\n",
            "After permute back: torch.Size([2, 158, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 158, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 158, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 158, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 158, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 158, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 159, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 159, 1280])\n",
            "After LayerNorm: torch.Size([2, 159, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([159, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([159, 2, 1280])\n",
            "After adding attn_output: torch.Size([159, 2, 1280])\n",
            "After permute back: torch.Size([2, 159, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 159, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 159, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 159, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 159, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 159, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 159, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 159, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 159, 1280])\n",
            "After LayerNorm: torch.Size([2, 159, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([159, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([159, 2, 1280])\n",
            "After adding attn_output: torch.Size([159, 2, 1280])\n",
            "After permute back: torch.Size([2, 159, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 159, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 159, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 159, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 159, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 159, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 160, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 160, 1280])\n",
            "After LayerNorm: torch.Size([2, 160, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([160, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([160, 2, 1280])\n",
            "After adding attn_output: torch.Size([160, 2, 1280])\n",
            "After permute back: torch.Size([2, 160, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 160, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 160, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 160, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 160, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 160, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 160, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 160, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 160, 1280])\n",
            "After LayerNorm: torch.Size([2, 160, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([160, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([160, 2, 1280])\n",
            "After adding attn_output: torch.Size([160, 2, 1280])\n",
            "After permute back: torch.Size([2, 160, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 160, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 160, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 160, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 160, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 160, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 161, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 161, 1280])\n",
            "After LayerNorm: torch.Size([2, 161, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([161, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([161, 2, 1280])\n",
            "After adding attn_output: torch.Size([161, 2, 1280])\n",
            "After permute back: torch.Size([2, 161, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 161, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 161, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 161, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 161, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 161, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 161, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 161, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 161, 1280])\n",
            "After LayerNorm: torch.Size([2, 161, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([161, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([161, 2, 1280])\n",
            "After adding attn_output: torch.Size([161, 2, 1280])\n",
            "After permute back: torch.Size([2, 161, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 161, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 161, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 161, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 161, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 161, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 162, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 162, 1280])\n",
            "After LayerNorm: torch.Size([2, 162, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([162, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([162, 2, 1280])\n",
            "After adding attn_output: torch.Size([162, 2, 1280])\n",
            "After permute back: torch.Size([2, 162, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 162, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 162, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 162, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 162, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 162, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 162, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 162, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 162, 1280])\n",
            "After LayerNorm: torch.Size([2, 162, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([162, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([162, 2, 1280])\n",
            "After adding attn_output: torch.Size([162, 2, 1280])\n",
            "After permute back: torch.Size([2, 162, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 162, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 162, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 162, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 162, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 162, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 163, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 163, 1280])\n",
            "After LayerNorm: torch.Size([2, 163, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([163, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([163, 2, 1280])\n",
            "After adding attn_output: torch.Size([163, 2, 1280])\n",
            "After permute back: torch.Size([2, 163, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 163, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 163, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 163, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 163, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 163, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 163, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 163, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 163, 1280])\n",
            "After LayerNorm: torch.Size([2, 163, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([163, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([163, 2, 1280])\n",
            "After adding attn_output: torch.Size([163, 2, 1280])\n",
            "After permute back: torch.Size([2, 163, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 163, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 163, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 163, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 163, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 163, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 164, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 164, 1280])\n",
            "After LayerNorm: torch.Size([2, 164, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([164, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([164, 2, 1280])\n",
            "After adding attn_output: torch.Size([164, 2, 1280])\n",
            "After permute back: torch.Size([2, 164, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 164, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 164, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 164, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 164, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 164, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 164, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 164, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 164, 1280])\n",
            "After LayerNorm: torch.Size([2, 164, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([164, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([164, 2, 1280])\n",
            "After adding attn_output: torch.Size([164, 2, 1280])\n",
            "After permute back: torch.Size([2, 164, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 164, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 164, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 164, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 164, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 164, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 165, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 165, 1280])\n",
            "After LayerNorm: torch.Size([2, 165, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([165, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([165, 2, 1280])\n",
            "After adding attn_output: torch.Size([165, 2, 1280])\n",
            "After permute back: torch.Size([2, 165, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 165, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 165, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 165, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 165, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 165, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 165, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 165, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 165, 1280])\n",
            "After LayerNorm: torch.Size([2, 165, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([165, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([165, 2, 1280])\n",
            "After adding attn_output: torch.Size([165, 2, 1280])\n",
            "After permute back: torch.Size([2, 165, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 165, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 165, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 165, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 165, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 165, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 166, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 166, 1280])\n",
            "After LayerNorm: torch.Size([2, 166, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([166, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([166, 2, 1280])\n",
            "After adding attn_output: torch.Size([166, 2, 1280])\n",
            "After permute back: torch.Size([2, 166, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 166, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 166, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 166, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 166, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 166, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 166, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 166, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 166, 1280])\n",
            "After LayerNorm: torch.Size([2, 166, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([166, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([166, 2, 1280])\n",
            "After adding attn_output: torch.Size([166, 2, 1280])\n",
            "After permute back: torch.Size([2, 166, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 166, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 166, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 166, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 166, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 166, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 167, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 167, 1280])\n",
            "After LayerNorm: torch.Size([2, 167, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([167, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([167, 2, 1280])\n",
            "After adding attn_output: torch.Size([167, 2, 1280])\n",
            "After permute back: torch.Size([2, 167, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 167, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 167, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 167, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 167, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 167, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 167, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 167, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 167, 1280])\n",
            "After LayerNorm: torch.Size([2, 167, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([167, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([167, 2, 1280])\n",
            "After adding attn_output: torch.Size([167, 2, 1280])\n",
            "After permute back: torch.Size([2, 167, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 167, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 167, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 167, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 167, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 167, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 168, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 168, 1280])\n",
            "After LayerNorm: torch.Size([2, 168, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([168, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([168, 2, 1280])\n",
            "After adding attn_output: torch.Size([168, 2, 1280])\n",
            "After permute back: torch.Size([2, 168, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 168, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 168, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 168, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 168, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 168, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 168, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 168, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 168, 1280])\n",
            "After LayerNorm: torch.Size([2, 168, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([168, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([168, 2, 1280])\n",
            "After adding attn_output: torch.Size([168, 2, 1280])\n",
            "After permute back: torch.Size([2, 168, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 168, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 168, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 168, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 168, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 168, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 169, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 169, 1280])\n",
            "After LayerNorm: torch.Size([2, 169, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([169, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([169, 2, 1280])\n",
            "After adding attn_output: torch.Size([169, 2, 1280])\n",
            "After permute back: torch.Size([2, 169, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 169, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 169, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 169, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 169, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 169, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 169, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 169, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 169, 1280])\n",
            "After LayerNorm: torch.Size([2, 169, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([169, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([169, 2, 1280])\n",
            "After adding attn_output: torch.Size([169, 2, 1280])\n",
            "After permute back: torch.Size([2, 169, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 169, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 169, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 169, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 169, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 169, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 170, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 170, 1280])\n",
            "After LayerNorm: torch.Size([2, 170, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([170, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([170, 2, 1280])\n",
            "After adding attn_output: torch.Size([170, 2, 1280])\n",
            "After permute back: torch.Size([2, 170, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 170, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 170, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 170, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 170, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 170, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 170, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 170, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 170, 1280])\n",
            "After LayerNorm: torch.Size([2, 170, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([170, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([170, 2, 1280])\n",
            "After adding attn_output: torch.Size([170, 2, 1280])\n",
            "After permute back: torch.Size([2, 170, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 170, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 170, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 170, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 170, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 170, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 171, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 171, 1280])\n",
            "After LayerNorm: torch.Size([2, 171, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([171, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([171, 2, 1280])\n",
            "After adding attn_output: torch.Size([171, 2, 1280])\n",
            "After permute back: torch.Size([2, 171, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 171, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 171, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 171, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 171, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 171, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 171, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 171, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 171, 1280])\n",
            "After LayerNorm: torch.Size([2, 171, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([171, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([171, 2, 1280])\n",
            "After adding attn_output: torch.Size([171, 2, 1280])\n",
            "After permute back: torch.Size([2, 171, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 171, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 171, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 171, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 171, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 171, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 172, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 172, 1280])\n",
            "After LayerNorm: torch.Size([2, 172, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([172, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([172, 2, 1280])\n",
            "After adding attn_output: torch.Size([172, 2, 1280])\n",
            "After permute back: torch.Size([2, 172, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 172, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 172, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 172, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 172, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 172, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 172, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 172, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 172, 1280])\n",
            "After LayerNorm: torch.Size([2, 172, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([172, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([172, 2, 1280])\n",
            "After adding attn_output: torch.Size([172, 2, 1280])\n",
            "After permute back: torch.Size([2, 172, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 172, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 172, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 172, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 172, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 172, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 173, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 173, 1280])\n",
            "After LayerNorm: torch.Size([2, 173, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([173, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([173, 2, 1280])\n",
            "After adding attn_output: torch.Size([173, 2, 1280])\n",
            "After permute back: torch.Size([2, 173, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 173, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 173, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 173, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 173, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 173, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 173, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 173, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 173, 1280])\n",
            "After LayerNorm: torch.Size([2, 173, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([173, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([173, 2, 1280])\n",
            "After adding attn_output: torch.Size([173, 2, 1280])\n",
            "After permute back: torch.Size([2, 173, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 173, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 173, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 173, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 173, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 173, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 174, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 174, 1280])\n",
            "After LayerNorm: torch.Size([2, 174, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([174, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([174, 2, 1280])\n",
            "After adding attn_output: torch.Size([174, 2, 1280])\n",
            "After permute back: torch.Size([2, 174, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 174, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 174, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 174, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 174, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 174, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 174, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 174, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 174, 1280])\n",
            "After LayerNorm: torch.Size([2, 174, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([174, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([174, 2, 1280])\n",
            "After adding attn_output: torch.Size([174, 2, 1280])\n",
            "After permute back: torch.Size([2, 174, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 174, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 174, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 174, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 174, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 174, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 175, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 175, 1280])\n",
            "After LayerNorm: torch.Size([2, 175, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([175, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([175, 2, 1280])\n",
            "After adding attn_output: torch.Size([175, 2, 1280])\n",
            "After permute back: torch.Size([2, 175, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 175, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 175, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 175, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 175, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 175, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 175, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 175, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 175, 1280])\n",
            "After LayerNorm: torch.Size([2, 175, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([175, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([175, 2, 1280])\n",
            "After adding attn_output: torch.Size([175, 2, 1280])\n",
            "After permute back: torch.Size([2, 175, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 175, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 175, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 175, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 175, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 175, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 176, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 176, 1280])\n",
            "After LayerNorm: torch.Size([2, 176, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([176, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([176, 2, 1280])\n",
            "After adding attn_output: torch.Size([176, 2, 1280])\n",
            "After permute back: torch.Size([2, 176, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 176, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 176, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 176, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 176, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 176, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 176, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 176, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 176, 1280])\n",
            "After LayerNorm: torch.Size([2, 176, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([176, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([176, 2, 1280])\n",
            "After adding attn_output: torch.Size([176, 2, 1280])\n",
            "After permute back: torch.Size([2, 176, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 176, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 176, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 176, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 176, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 176, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 177, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 177, 1280])\n",
            "After LayerNorm: torch.Size([2, 177, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([177, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([177, 2, 1280])\n",
            "After adding attn_output: torch.Size([177, 2, 1280])\n",
            "After permute back: torch.Size([2, 177, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 177, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 177, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 177, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 177, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 177, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 177, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 177, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 177, 1280])\n",
            "After LayerNorm: torch.Size([2, 177, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([177, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([177, 2, 1280])\n",
            "After adding attn_output: torch.Size([177, 2, 1280])\n",
            "After permute back: torch.Size([2, 177, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 177, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 177, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 177, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 177, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 177, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 178, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 178, 1280])\n",
            "After LayerNorm: torch.Size([2, 178, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([178, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([178, 2, 1280])\n",
            "After adding attn_output: torch.Size([178, 2, 1280])\n",
            "After permute back: torch.Size([2, 178, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 178, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 178, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 178, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 178, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 178, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 178, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 178, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 178, 1280])\n",
            "After LayerNorm: torch.Size([2, 178, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([178, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([178, 2, 1280])\n",
            "After adding attn_output: torch.Size([178, 2, 1280])\n",
            "After permute back: torch.Size([2, 178, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 178, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 178, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 178, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 178, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 178, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 179, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 179, 1280])\n",
            "After LayerNorm: torch.Size([2, 179, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([179, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([179, 2, 1280])\n",
            "After adding attn_output: torch.Size([179, 2, 1280])\n",
            "After permute back: torch.Size([2, 179, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 179, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 179, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 179, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 179, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 179, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 179, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 179, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 179, 1280])\n",
            "After LayerNorm: torch.Size([2, 179, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([179, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([179, 2, 1280])\n",
            "After adding attn_output: torch.Size([179, 2, 1280])\n",
            "After permute back: torch.Size([2, 179, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 179, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 179, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 179, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 179, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 179, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 180, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 180, 1280])\n",
            "After LayerNorm: torch.Size([2, 180, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([180, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([180, 2, 1280])\n",
            "After adding attn_output: torch.Size([180, 2, 1280])\n",
            "After permute back: torch.Size([2, 180, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 180, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 180, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 180, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 180, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 180, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 180, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 180, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 180, 1280])\n",
            "After LayerNorm: torch.Size([2, 180, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([180, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([180, 2, 1280])\n",
            "After adding attn_output: torch.Size([180, 2, 1280])\n",
            "After permute back: torch.Size([2, 180, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 180, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 180, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 180, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 180, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 180, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 181, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 181, 1280])\n",
            "After LayerNorm: torch.Size([2, 181, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([181, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([181, 2, 1280])\n",
            "After adding attn_output: torch.Size([181, 2, 1280])\n",
            "After permute back: torch.Size([2, 181, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 181, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 181, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 181, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 181, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 181, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 181, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 181, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 181, 1280])\n",
            "After LayerNorm: torch.Size([2, 181, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([181, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([181, 2, 1280])\n",
            "After adding attn_output: torch.Size([181, 2, 1280])\n",
            "After permute back: torch.Size([2, 181, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 181, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 181, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 181, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 181, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 181, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 182, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 182, 1280])\n",
            "After LayerNorm: torch.Size([2, 182, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([182, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([182, 2, 1280])\n",
            "After adding attn_output: torch.Size([182, 2, 1280])\n",
            "After permute back: torch.Size([2, 182, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 182, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 182, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 182, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 182, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 182, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 182, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 182, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 182, 1280])\n",
            "After LayerNorm: torch.Size([2, 182, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([182, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([182, 2, 1280])\n",
            "After adding attn_output: torch.Size([182, 2, 1280])\n",
            "After permute back: torch.Size([2, 182, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 182, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 182, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 182, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 182, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 182, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 183, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 183, 1280])\n",
            "After LayerNorm: torch.Size([2, 183, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([183, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([183, 2, 1280])\n",
            "After adding attn_output: torch.Size([183, 2, 1280])\n",
            "After permute back: torch.Size([2, 183, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 183, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 183, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 183, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 183, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 183, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 183, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 183, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 183, 1280])\n",
            "After LayerNorm: torch.Size([2, 183, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([183, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([183, 2, 1280])\n",
            "After adding attn_output: torch.Size([183, 2, 1280])\n",
            "After permute back: torch.Size([2, 183, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 183, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 183, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 183, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 183, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 183, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 184, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 184, 1280])\n",
            "After LayerNorm: torch.Size([2, 184, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([184, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([184, 2, 1280])\n",
            "After adding attn_output: torch.Size([184, 2, 1280])\n",
            "After permute back: torch.Size([2, 184, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 184, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 184, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 184, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 184, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 184, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 184, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 184, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 184, 1280])\n",
            "After LayerNorm: torch.Size([2, 184, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([184, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([184, 2, 1280])\n",
            "After adding attn_output: torch.Size([184, 2, 1280])\n",
            "After permute back: torch.Size([2, 184, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 184, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 184, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 184, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 184, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 184, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 185, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 185, 1280])\n",
            "After LayerNorm: torch.Size([2, 185, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([185, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([185, 2, 1280])\n",
            "After adding attn_output: torch.Size([185, 2, 1280])\n",
            "After permute back: torch.Size([2, 185, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 185, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 185, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 185, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 185, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 185, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 185, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 185, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 185, 1280])\n",
            "After LayerNorm: torch.Size([2, 185, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([185, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([185, 2, 1280])\n",
            "After adding attn_output: torch.Size([185, 2, 1280])\n",
            "After permute back: torch.Size([2, 185, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 185, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 185, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 185, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 185, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 185, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 186, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 186, 1280])\n",
            "After LayerNorm: torch.Size([2, 186, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([186, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([186, 2, 1280])\n",
            "After adding attn_output: torch.Size([186, 2, 1280])\n",
            "After permute back: torch.Size([2, 186, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 186, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 186, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 186, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 186, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 186, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 186, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 186, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 186, 1280])\n",
            "After LayerNorm: torch.Size([2, 186, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([186, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([186, 2, 1280])\n",
            "After adding attn_output: torch.Size([186, 2, 1280])\n",
            "After permute back: torch.Size([2, 186, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 186, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 186, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 186, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 186, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 186, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 187, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 187, 1280])\n",
            "After LayerNorm: torch.Size([2, 187, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([187, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([187, 2, 1280])\n",
            "After adding attn_output: torch.Size([187, 2, 1280])\n",
            "After permute back: torch.Size([2, 187, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 187, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 187, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 187, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 187, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 187, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 187, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 187, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 187, 1280])\n",
            "After LayerNorm: torch.Size([2, 187, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([187, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([187, 2, 1280])\n",
            "After adding attn_output: torch.Size([187, 2, 1280])\n",
            "After permute back: torch.Size([2, 187, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 187, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 187, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 187, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 187, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 187, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 188, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 188, 1280])\n",
            "After LayerNorm: torch.Size([2, 188, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([188, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([188, 2, 1280])\n",
            "After adding attn_output: torch.Size([188, 2, 1280])\n",
            "After permute back: torch.Size([2, 188, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 188, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 188, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 188, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 188, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 188, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 188, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 188, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 188, 1280])\n",
            "After LayerNorm: torch.Size([2, 188, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([188, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([188, 2, 1280])\n",
            "After adding attn_output: torch.Size([188, 2, 1280])\n",
            "After permute back: torch.Size([2, 188, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 188, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 188, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 188, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 188, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 188, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 189, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 189, 1280])\n",
            "After LayerNorm: torch.Size([2, 189, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([189, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([189, 2, 1280])\n",
            "After adding attn_output: torch.Size([189, 2, 1280])\n",
            "After permute back: torch.Size([2, 189, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 189, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 189, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 189, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 189, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 189, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 189, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 189, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 189, 1280])\n",
            "After LayerNorm: torch.Size([2, 189, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([189, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([189, 2, 1280])\n",
            "After adding attn_output: torch.Size([189, 2, 1280])\n",
            "After permute back: torch.Size([2, 189, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 189, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 189, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 189, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 189, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 189, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 190, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 190, 1280])\n",
            "After LayerNorm: torch.Size([2, 190, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([190, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([190, 2, 1280])\n",
            "After adding attn_output: torch.Size([190, 2, 1280])\n",
            "After permute back: torch.Size([2, 190, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 190, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 190, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 190, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 190, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 190, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 190, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 190, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 190, 1280])\n",
            "After LayerNorm: torch.Size([2, 190, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([190, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([190, 2, 1280])\n",
            "After adding attn_output: torch.Size([190, 2, 1280])\n",
            "After permute back: torch.Size([2, 190, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 190, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 190, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 190, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 190, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 190, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 191, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 191, 1280])\n",
            "After LayerNorm: torch.Size([2, 191, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([191, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([191, 2, 1280])\n",
            "After adding attn_output: torch.Size([191, 2, 1280])\n",
            "After permute back: torch.Size([2, 191, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 191, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 191, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 191, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 191, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 191, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 191, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 191, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 191, 1280])\n",
            "After LayerNorm: torch.Size([2, 191, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([191, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([191, 2, 1280])\n",
            "After adding attn_output: torch.Size([191, 2, 1280])\n",
            "After permute back: torch.Size([2, 191, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 191, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 191, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 191, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 191, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 191, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 192, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 192, 1280])\n",
            "After LayerNorm: torch.Size([2, 192, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([192, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([192, 2, 1280])\n",
            "After adding attn_output: torch.Size([192, 2, 1280])\n",
            "After permute back: torch.Size([2, 192, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 192, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 192, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 192, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 192, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 192, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 192, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 192, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 192, 1280])\n",
            "After LayerNorm: torch.Size([2, 192, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([192, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([192, 2, 1280])\n",
            "After adding attn_output: torch.Size([192, 2, 1280])\n",
            "After permute back: torch.Size([2, 192, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 192, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 192, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 192, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 192, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 192, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 193, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 193, 1280])\n",
            "After LayerNorm: torch.Size([2, 193, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([193, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([193, 2, 1280])\n",
            "After adding attn_output: torch.Size([193, 2, 1280])\n",
            "After permute back: torch.Size([2, 193, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 193, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 193, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 193, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 193, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 193, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 193, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 193, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 193, 1280])\n",
            "After LayerNorm: torch.Size([2, 193, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([193, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([193, 2, 1280])\n",
            "After adding attn_output: torch.Size([193, 2, 1280])\n",
            "After permute back: torch.Size([2, 193, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 193, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 193, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 193, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 193, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 193, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 194, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 194, 1280])\n",
            "After LayerNorm: torch.Size([2, 194, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([194, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([194, 2, 1280])\n",
            "After adding attn_output: torch.Size([194, 2, 1280])\n",
            "After permute back: torch.Size([2, 194, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 194, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 194, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 194, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 194, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 194, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 194, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 194, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 194, 1280])\n",
            "After LayerNorm: torch.Size([2, 194, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([194, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([194, 2, 1280])\n",
            "After adding attn_output: torch.Size([194, 2, 1280])\n",
            "After permute back: torch.Size([2, 194, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 194, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 194, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 194, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 194, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 194, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 195, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 195, 1280])\n",
            "After LayerNorm: torch.Size([2, 195, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([195, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([195, 2, 1280])\n",
            "After adding attn_output: torch.Size([195, 2, 1280])\n",
            "After permute back: torch.Size([2, 195, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 195, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 195, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 195, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 195, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 195, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 195, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 195, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 195, 1280])\n",
            "After LayerNorm: torch.Size([2, 195, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([195, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([195, 2, 1280])\n",
            "After adding attn_output: torch.Size([195, 2, 1280])\n",
            "After permute back: torch.Size([2, 195, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 195, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 195, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 195, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 195, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 195, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 196, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 196, 1280])\n",
            "After LayerNorm: torch.Size([2, 196, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([196, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([196, 2, 1280])\n",
            "After adding attn_output: torch.Size([196, 2, 1280])\n",
            "After permute back: torch.Size([2, 196, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 196, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 196, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 196, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 196, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 196, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 196, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 196, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 196, 1280])\n",
            "After LayerNorm: torch.Size([2, 196, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([196, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([196, 2, 1280])\n",
            "After adding attn_output: torch.Size([196, 2, 1280])\n",
            "After permute back: torch.Size([2, 196, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 196, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 196, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 196, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 196, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 196, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 197, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 197, 1280])\n",
            "After LayerNorm: torch.Size([2, 197, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([197, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([197, 2, 1280])\n",
            "After adding attn_output: torch.Size([197, 2, 1280])\n",
            "After permute back: torch.Size([2, 197, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 197, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 197, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 197, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 197, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 197, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 197, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 197, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 197, 1280])\n",
            "After LayerNorm: torch.Size([2, 197, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([197, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([197, 2, 1280])\n",
            "After adding attn_output: torch.Size([197, 2, 1280])\n",
            "After permute back: torch.Size([2, 197, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 197, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 197, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 197, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 197, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 197, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 198, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 198, 1280])\n",
            "After LayerNorm: torch.Size([2, 198, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([198, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([198, 2, 1280])\n",
            "After adding attn_output: torch.Size([198, 2, 1280])\n",
            "After permute back: torch.Size([2, 198, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 198, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 198, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 198, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 198, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 198, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 198, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 198, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 198, 1280])\n",
            "After LayerNorm: torch.Size([2, 198, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([198, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([198, 2, 1280])\n",
            "After adding attn_output: torch.Size([198, 2, 1280])\n",
            "After permute back: torch.Size([2, 198, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 198, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 198, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 198, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 198, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 198, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 199, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 199, 1280])\n",
            "After LayerNorm: torch.Size([2, 199, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([199, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([199, 2, 1280])\n",
            "After adding attn_output: torch.Size([199, 2, 1280])\n",
            "After permute back: torch.Size([2, 199, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 199, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 199, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 199, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 199, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 199, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 199, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 199, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 199, 1280])\n",
            "After LayerNorm: torch.Size([2, 199, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([199, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([199, 2, 1280])\n",
            "After adding attn_output: torch.Size([199, 2, 1280])\n",
            "After permute back: torch.Size([2, 199, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 199, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 199, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 199, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 199, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 199, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 200, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 200, 1280])\n",
            "After LayerNorm: torch.Size([2, 200, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([200, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([200, 2, 1280])\n",
            "After adding attn_output: torch.Size([200, 2, 1280])\n",
            "After permute back: torch.Size([2, 200, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 200, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 200, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 200, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 200, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 200, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 200, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 200, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 200, 1280])\n",
            "After LayerNorm: torch.Size([2, 200, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([200, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([200, 2, 1280])\n",
            "After adding attn_output: torch.Size([200, 2, 1280])\n",
            "After permute back: torch.Size([2, 200, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 200, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 200, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 200, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 200, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 200, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 201, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 201, 1280])\n",
            "After LayerNorm: torch.Size([2, 201, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([201, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([201, 2, 1280])\n",
            "After adding attn_output: torch.Size([201, 2, 1280])\n",
            "After permute back: torch.Size([2, 201, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 201, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 201, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 201, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 201, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 201, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 201, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 201, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 201, 1280])\n",
            "After LayerNorm: torch.Size([2, 201, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([201, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([201, 2, 1280])\n",
            "After adding attn_output: torch.Size([201, 2, 1280])\n",
            "After permute back: torch.Size([2, 201, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 201, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 201, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 201, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 201, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 201, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 202, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 202, 1280])\n",
            "After LayerNorm: torch.Size([2, 202, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([202, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([202, 2, 1280])\n",
            "After adding attn_output: torch.Size([202, 2, 1280])\n",
            "After permute back: torch.Size([2, 202, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 202, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 202, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 202, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 202, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 202, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 202, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 202, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 202, 1280])\n",
            "After LayerNorm: torch.Size([2, 202, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([202, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([202, 2, 1280])\n",
            "After adding attn_output: torch.Size([202, 2, 1280])\n",
            "After permute back: torch.Size([2, 202, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 202, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 202, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 202, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 202, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 202, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 203, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 203, 1280])\n",
            "After LayerNorm: torch.Size([2, 203, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([203, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([203, 2, 1280])\n",
            "After adding attn_output: torch.Size([203, 2, 1280])\n",
            "After permute back: torch.Size([2, 203, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 203, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 203, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 203, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 203, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 203, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 203, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 203, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 203, 1280])\n",
            "After LayerNorm: torch.Size([2, 203, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([203, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([203, 2, 1280])\n",
            "After adding attn_output: torch.Size([203, 2, 1280])\n",
            "After permute back: torch.Size([2, 203, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 203, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 203, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 203, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 203, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 203, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 204, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 204, 1280])\n",
            "After LayerNorm: torch.Size([2, 204, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([204, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([204, 2, 1280])\n",
            "After adding attn_output: torch.Size([204, 2, 1280])\n",
            "After permute back: torch.Size([2, 204, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 204, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 204, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 204, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 204, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 204, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 204, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 204, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 204, 1280])\n",
            "After LayerNorm: torch.Size([2, 204, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([204, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([204, 2, 1280])\n",
            "After adding attn_output: torch.Size([204, 2, 1280])\n",
            "After permute back: torch.Size([2, 204, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 204, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 204, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 204, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 204, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 204, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 205, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 205, 1280])\n",
            "After LayerNorm: torch.Size([2, 205, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([205, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([205, 2, 1280])\n",
            "After adding attn_output: torch.Size([205, 2, 1280])\n",
            "After permute back: torch.Size([2, 205, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 205, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 205, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 205, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 205, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 205, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 205, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 205, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 205, 1280])\n",
            "After LayerNorm: torch.Size([2, 205, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([205, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([205, 2, 1280])\n",
            "After adding attn_output: torch.Size([205, 2, 1280])\n",
            "After permute back: torch.Size([2, 205, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 205, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 205, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 205, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 205, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 205, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 206, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 206, 1280])\n",
            "After LayerNorm: torch.Size([2, 206, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([206, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([206, 2, 1280])\n",
            "After adding attn_output: torch.Size([206, 2, 1280])\n",
            "After permute back: torch.Size([2, 206, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 206, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 206, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 206, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 206, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 206, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 206, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 206, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 206, 1280])\n",
            "After LayerNorm: torch.Size([2, 206, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([206, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([206, 2, 1280])\n",
            "After adding attn_output: torch.Size([206, 2, 1280])\n",
            "After permute back: torch.Size([2, 206, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 206, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 206, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 206, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 206, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 206, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 207, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 207, 1280])\n",
            "After LayerNorm: torch.Size([2, 207, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([207, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([207, 2, 1280])\n",
            "After adding attn_output: torch.Size([207, 2, 1280])\n",
            "After permute back: torch.Size([2, 207, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 207, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 207, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 207, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 207, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 207, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 207, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 207, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 207, 1280])\n",
            "After LayerNorm: torch.Size([2, 207, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([207, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([207, 2, 1280])\n",
            "After adding attn_output: torch.Size([207, 2, 1280])\n",
            "After permute back: torch.Size([2, 207, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 207, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 207, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 207, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 207, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 207, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n",
            "processed_prot1 embeddings\n",
            "prepare gen seq\n",
            "embed generated seq\n",
            "parelleltransfomr\n",
            "torch.Size([2, 208, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 208, 1280])\n",
            "After LayerNorm: torch.Size([2, 208, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([208, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([208, 2, 1280])\n",
            "After adding attn_output: torch.Size([208, 2, 1280])\n",
            "After permute back: torch.Size([2, 208, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 208, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 208, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 208, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 208, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 208, 1280])\n",
            "gated cross attn\n",
            "torch.Size([2, 208, 1280])\n",
            "parelleltransfomr\n",
            "torch.Size([2, 208, 1280])\n",
            "Input to ParallelTransformerBlock: torch.Size([2, 208, 1280])\n",
            "After LayerNorm: torch.Size([2, 208, 1280])\n",
            "After permute for MultiheadAttention: torch.Size([208, 2, 1280])\n",
            "After MultiheadAttention: torch.Size([208, 2, 1280])\n",
            "After adding attn_output: torch.Size([208, 2, 1280])\n",
            "After permute back: torch.Size([2, 208, 1280])\n",
            "Input to Linear Layer: torch.Size([2, 208, 1280])\n",
            "Output from Linear Layer: torch.Size([2, 208, 10240])\n",
            "Input to Linear Layer: torch.Size([2, 208, 5120])\n",
            "Output from Linear Layer: torch.Size([2, 208, 1280])\n",
            "Output from ParallelTransformerBlock: torch.Size([2, 208, 1280])\n",
            "process gen seq thru model layers\n",
            "torch.Size([2, 1, 523, 1280])\n",
            "torch.Size([4, 1, 1280])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5287ee53fee0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}: Training Loss: {train_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-a9853e1edbd2>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate over each token in the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Predict the next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_protein_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Flatten output for loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1d0a97c003c4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prot1_embeddings, generated_sequence)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprot1_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Process prot1 embeddings through perceiver resampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mprocessed_prot1_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceiver_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot1_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_prot1 embeddings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-93ed79cc21fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-93ed79cc21fd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, latents)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# the paper differs from Perceiver in which they also concat the key / values derived from the latents to be attended to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mkv_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.56 GiB of which 16.56 MiB is free. Process 2206 has 39.54 GiB memory in use. Of the allocated memory 37.54 GiB is allocated by PyTorch, and 645.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "protT5_tokenizer"
      ],
      "metadata": {
        "id": "so-4BEHlgsV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}