{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7rhuRCHcBuW"
      },
      "source": [
        "### **Make a new dataset**\n",
        "- target seq\n",
        "- binder seq\n",
        "- motif seq\n",
        "- cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raFP6jfJKxXF",
        "outputId": "f400f774-9061-439b-da9c-d7d6d94e7b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch\n",
        "import re\n",
        "!pip install sentencepiece\n",
        "import sentencepiece\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4w137bz4JVPB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Programmable Biology Group/Srikar/Code/proteins/flamingo-ppi-gen/data_dump/per-residue-dataset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF6VU00nJM0G",
        "outputId": "4bf64f85-367e-4051-f857-4e69e4c5c67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
        "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model = model.half() if device.type == 'cuda' else model.full()\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "47Uq6WcVJR8r"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_protT5_tokens(sequences):\n",
        "    tokens_dict = {}\n",
        "    # Wrap the sequence iteration with tqdm for a progress bar\n",
        "    for sequence in tqdm(sequences, desc=\"Generating...\"):\n",
        "        # Process sequence\n",
        "        #print(len(sequence))\n",
        "        processed_seq = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence)))\n",
        "        #print(len(processed_seq))\n",
        "        # Tokenize and encode\n",
        "        ids = tokenizer(processed_seq, add_special_tokens=True, return_tensors=\"pt\",padding='longest')\n",
        "        input_ids = ids['input_ids'].to(device)\n",
        "        tokens_dict[sequence] = input_ids.squeeze().tolist()\n",
        "    return tokens_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ibs4RGaLKoZI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def preprocess_snp_data(file_path):\n",
        "    # Read the dataset\n",
        "    snp_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Function to transform energy scores\n",
        "    def transform_energy_scores(energy_scores):\n",
        "        transformed_scores = []\n",
        "        for score in energy_scores:\n",
        "            # Replace sequences of spaces/newlines with a comma\n",
        "            score = re.sub(r'[\\s\\n]+', ',', score)\n",
        "            # Remove a comma after an opening square bracket\n",
        "            score = re.sub(r'\\[\\s*,', '[', score)\n",
        "            # Remove leading commas/whitespace\n",
        "            score = re.sub(r'^[\\s,]+', '', score)\n",
        "            transformed_scores.append(score)\n",
        "        return transformed_scores\n",
        "\n",
        "    # Apply transformations\n",
        "    snp_df['energy_scores'] = transform_energy_scores(snp_df['energy_scores'])\n",
        "    snp_df['energy_scores_lengths'] = snp_df['energy_scores'].apply(\n",
        "        lambda x: x.count(',') + 1 - (1 if x.startswith(',') else 0)\n",
        "    )\n",
        "\n",
        "    # Calculate lengths for other columns\n",
        "    snp_df['peptide_source_RCSB_lengths'] = snp_df['peptide_source_RCSB'].apply(len)\n",
        "    snp_df['protein_RCSB_lengths'] = snp_df['protein_RCSB'].apply(len)\n",
        "    snp_df['protein_derived_seq_length'] = snp_df['protein_derived_sequence'].apply(len)\n",
        "    snp_df['peptide_derived_seq_length'] = snp_df['peptide_derived_sequence'].apply(len)\n",
        "\n",
        "    # Calculate matching lengths count (optional, depending on your needs)\n",
        "    snp_df['matching_lengths_count'] = (snp_df['energy_scores_lengths'] == snp_df['peptide_derived_seq_length']).sum()\n",
        "\n",
        "    return snp_df\n",
        "\n",
        "# Applying the preprocessing pipeline to each dataset\n",
        "test_snp = preprocess_snp_data('testing_dataset.csv')\n",
        "train_snp = preprocess_snp_data('training_dataset.csv')\n",
        "val_snp = preprocess_snp_data('validation_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaneY7t_K0Aa",
        "outputId": "cc140b4c-795d-4e0d-82e1-18e9d71dd92f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5EncoderModel(\n",
              "  (shared): Embedding(128, 1024)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(128, 1024)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 32)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
              "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-23): 23 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
              "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
              "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
        "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "# model = model.half() if device.type == 'cuda' else model.full()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0llJJwgaK5F2",
        "outputId": "61891fd6-0400-4830-f97a-4a89f3f8ff4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating...: 100%|██████████| 9665/9665 [00:10<00:00, 915.49it/s] \n"
          ]
        }
      ],
      "source": [
        "unique_seqs = pd.concat([train_snp['peptide_derived_sequence'], train_snp['protein_derived_sequence'],\n",
        "                         test_snp['peptide_derived_sequence'], test_snp['protein_derived_sequence'],\n",
        "                         val_snp['peptide_derived_sequence'], val_snp['protein_derived_sequence']]).unique()\n",
        "\n",
        "protT5_tokens = generate_protT5_tokens(unique_seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EJAJtKEzcV1j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.functional import pad\n",
        "\n",
        "class ProteinInteractionDataset(Dataset):\n",
        "    def __init__(self, dataframe, protT5_tokens):\n",
        "        self.protT5_model = T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "        self.protT5_tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "        self.dataframe = dataframe\n",
        "        self.protT5_tokens = protT5_tokens\n",
        "        # Determine the maximum length\n",
        "        self.max_length_tokenized = max(len(self.protT5_tokens[seq]) for seq in dataframe['peptide_derived_sequence'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        peptide_seq = self.dataframe.iloc[idx]['peptide_derived_sequence']\n",
        "        protein_seq = self.dataframe.iloc[idx]['protein_derived_sequence']\n",
        "        energy_scores = self.dataframe.iloc[idx]['energy_scores']\n",
        "        clusters = self.dataframe.iloc[idx]['cluster']\n",
        "\n",
        "        tokenized_peptide_seq = self.protT5_tokens[peptide_seq]\n",
        "        tokenized_protein_seq = self.protT5_tokens[protein_seq]\n",
        "\n",
        "        # Process the energy_scores\n",
        "        energy_scores = re.findall(r'-?\\d+\\.?\\d*(?:e[-+]?\\d+)?', energy_scores)\n",
        "        energy_scores = [float(score) for score in energy_scores]\n",
        "        energy_scores = one_hot_encode_energy_scores(energy_scores)\n",
        "        # Pad the energy scores -- max length of all should be equal\n",
        "        energy_scores_padded = pad(torch.tensor(energy_scores), (0, self.max_length_tokenized - len(energy_scores)), \"constant\", 0)\n",
        "        # Pad the sequences\n",
        "        tokenized_peptide_seq_padded = pad(torch.tensor(tokenized_peptide_seq, dtype=torch.long), (0, self.max_length_tokenized - len(tokenized_peptide_seq)), \"constant\", 0)\n",
        "        tokenized_protein_seq_padded = pad(torch.tensor(tokenized_protein_seq, dtype=torch.long), (0, self.max_length_tokenized - len(tokenized_protein_seq)), \"constant\", 0)\n",
        "        return energy_scores_padded, tokenized_peptide_seq_padded, tokenized_protein_seq_padded, clusters\n",
        "\n",
        "def one_hot_encode_energy_scores(scores):\n",
        "        # Assuming 'scores' is a list of energy score values\n",
        "        return [1 if score <= -1 else 0 for score in scores]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uQHCeqEiK5yn"
      },
      "outputs": [],
      "source": [
        "# Create datasets with tokenizer\n",
        "train_dataset = ProteinInteractionDataset(train_snp, protT5_tokens)\n",
        "test_dataset = ProteinInteractionDataset(test_snp, protT5_tokens)\n",
        "val_dataset = ProteinInteractionDataset(val_snp, protT5_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BHVnA7vpLTAw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_batch_size = 2\n",
        "test_batch_size = 2\n",
        "val_batch_size = 2\n",
        "\n",
        "# Create the DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8pMULBaC_qS"
      },
      "source": [
        "### **Background Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "General"
      ],
      "metadata": {
        "id": "wagP-3zdrZyt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1ACmWOYMDFLA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from transformers import RobertaModel  # Assuming use of Hugging Face's transformer models\n",
        "\n",
        "# Helper Functions\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def set_module_requires_grad_(module, requires_grad):\n",
        "    for param in module.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "\n",
        "def freeze_model_and_make_eval_(model):\n",
        "    model.eval()\n",
        "    set_module_requires_grad_(model, False)\n",
        "\n",
        "# LayerNorm class\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.gain = nn.Parameter(torch.ones(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gain * (x - mean) / (std + self.eps)\n",
        "\n",
        "# Residual class\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "# SwiGLU activation function\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return F.silu(x[..., :x.shape[-1] // 2]) * x[..., x.shape[-1] // 2:]\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(x)\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gate = x.chunk(2, dim=-1)\n",
        "        return F.silu(gate) * x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Perciever+Cross Attn"
      ],
      "metadata": {
        "id": "x-rLhOM9rbsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install einops-exts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv4u1pLEQhdW",
        "outputId": "d0852c30-7491-4e68-8bd2-af4bab396e8e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: einops-exts in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: einops>=0.4 in /usr/local/lib/python3.10/dist-packages (from einops-exts) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ichz74-ADmOv"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:4096'\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops_exts import rearrange_many, repeat_many\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def FeedForward(dim, mult = 4):\n",
        "    inner_dim = int(dim * mult)\n",
        "    return nn.Sequential(\n",
        "        nn.LayerNorm(dim),\n",
        "        nn.Linear(dim, inner_dim, bias = False),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(inner_dim, dim, bias = False)\n",
        "    )\n",
        "\n",
        "class PerceiverAttention(nn.Module):\n",
        "    def __init__(self, *, dim, concatenated_dim, dim_head=64, heads=8):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm_media = nn.LayerNorm(dim)\n",
        "        self.norm_latents = nn.LayerNorm(dim)\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, x, latents):\n",
        "        x = self.norm_media(x)\n",
        "        latents = self.norm_latents(latents)\n",
        "\n",
        "        # print('x shape perciever attn:', x.shape)\n",
        "        # print('latents shape perceiver attn', latents.shape)\n",
        "\n",
        "        q = self.to_q(latents)\n",
        "        # print('q shape:',q.shape)\n",
        "\n",
        "        q = rearrange(q, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        q = q * self.scale\n",
        "\n",
        "\n",
        "        kv_input = torch.cat((x, latents), dim=1)\n",
        "        k, v = self.to_kv(kv_input).chunk(2, dim=-1)\n",
        "\n",
        "        # print('k shape:',k.shape)\n",
        "        # print('v shape:',v.shape)\n",
        "        k = rearrange(k, 'b n (h d) -> b h n d', h=self.heads)\n",
        "        v = rearrange(v, 'b n (h d) -> b h n d', h=self.heads)\n",
        "\n",
        "        # print('rearrangement in perceiver cross attn complete...')\n",
        "        # print('q shape:',q.shape)\n",
        "        # print('k shape:',k.shape)\n",
        "        # print('v shape:',v.shape)\n",
        "\n",
        "        sim = einsum('... i d, ... j d -> ... i j', q, k)\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "\n",
        "        return self.to_out(out)\n",
        "\n",
        "class PerceiverResampler(nn.Module):\n",
        "    def __init__(self, *, dim, depth, dim_head=64, heads=8, num_latents=64, concatenated_dim=2048):\n",
        "        super().__init__()\n",
        "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PerceiverAttention(dim=dim, concatenated_dim=concatenated_dim, dim_head=dim_head, heads=heads),\n",
        "                FeedForward(dim=dim)\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        latents = repeat(self.latents, 'n d -> b n d', b=x.shape[0])\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            latents = attn(x, latents) + latents\n",
        "            latents = ff(latents) + latents\n",
        "\n",
        "        return latents\n",
        "\n",
        "class MaskedCrossAttention(nn.Module):\n",
        "    def __init__(self, *, dim, concatenated_dim=2048, dim_head=64, heads=8, only_attend_immediate_media=True):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        inner_dim = dim_head * heads\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
        "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
        "        self.only_attend_immediate_media = only_attend_immediate_media\n",
        "\n",
        "    def forward(self, x, media, media_locations=None):\n",
        "        b, t, _ = x.shape\n",
        "        _, m, _ = media.shape\n",
        "        h = self.heads\n",
        "\n",
        "        x = self.norm(x)\n",
        "        q = self.to_q(x)\n",
        "        q = rearrange(q, 'b n (h d) -> b h n d', h=h)\n",
        "\n",
        "        # No need to reshape media as it's already 3D\n",
        "        k, v = self.to_kv(media).chunk(2, dim=-1)\n",
        "        k = rearrange(k, 'b n (h d) -> b h n d', h=h)\n",
        "        v = rearrange(v, 'b n (h d) -> b h n d', h=h)\n",
        "\n",
        "        q = q * self.scale\n",
        "        sim = einsum('... i d, ... j d -> ... i j', q, k)\n",
        "\n",
        "        if media_locations is not None:\n",
        "            mask = media_locations.unsqueeze(1).unsqueeze(2)\n",
        "            mask = rearrange(mask, 'b n -> b 1 n 1')\n",
        "            sim = sim.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)', h=self.heads)\n",
        "\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class GatedCrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, *, dim, dim_head=64, heads=8, ff_mult=4, only_attend_immediate_media=True):\n",
        "        super().__init__()\n",
        "        self.attn = MaskedCrossAttention(dim=dim, concatenated_dim=2048, dim_head=dim_head, heads=heads, only_attend_immediate_media=only_attend_immediate_media)\n",
        "        self.attn_gate = nn.Parameter(torch.tensor([0.]))\n",
        "        self.ff = FeedForward(dim, mult=ff_mult)\n",
        "        self.ff_gate = nn.Parameter(torch.tensor([0.]))\n",
        "\n",
        "    def forward(self, x, media, media_locations=None):\n",
        "        gate = self.attn_gate.tanh()\n",
        "        x = self.attn(x, media, media_locations=media_locations) * gate + x\n",
        "        x = self.ff(x) * self.ff_gate.tanh() + x\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJBI5IltgLPW"
      },
      "source": [
        "### **ProtFlamingo**\n",
        "- input = tokenized target,binder & motif encoding\n",
        "- protT5 embed tokenized AA seqs (text), motif emb (image)\n",
        "- goal: complete binder seq (text completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ykjBoYmafWtO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "class ProtFlamingoLearnedEmbedding(nn.Module):\n",
        "    def __init__(self, num_tokens, depth, dim_head=64, heads=8, ff_mult=4, cross_attn_every=3, perceiver_num_latents=64, perceiver_depth=2):\n",
        "        super().__init__()\n",
        "        self.motif_embedding_projection = nn.Embedding(2, 1024)  # Binary one-hot encoding to 1024 dimensions\n",
        "\n",
        "        # Load ProtT5 model and tokenizer\n",
        "        self.protT5_model = T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "        self.protT5_tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "\n",
        "        # Access the decoder blocks from ProtT5 model\n",
        "        self.decoder_blocks = self.protT5_model.decoder.block\n",
        "\n",
        "        # Intersperse GatedCrossAttentionBlocks within the T5 decoder blocks\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for i, block in enumerate(self.decoder_blocks):\n",
        "            self.layers.append(block)\n",
        "            if i % cross_attn_every == 0 and i != 0:\n",
        "                self.layers.append(GatedCrossAttentionBlock(dim=self.protT5_model.config.d_model, dim_head=dim_head, heads=heads))\n",
        "\n",
        "        self.perceiver_resampler = PerceiverResampler(dim=self.protT5_model.config.d_model, depth=perceiver_depth, dim_head=dim_head, heads=heads, num_latents=perceiver_num_latents)\n",
        "        self.expand_seq_len = nn.Linear(dim_head, 983)\n",
        "\n",
        "    def forward(self, tokenized_target_seq, tokenized_binder_seq, motif_one_hot):\n",
        "        motif_embeddings = self.motif_embedding_projection(motif_one_hot.long())\n",
        "        target_embeddings = self.generate_protT5_embeddings(tokenized_target_seq)\n",
        "        binder_embeddings = self.generate_protT5_embeddings(tokenized_binder_seq)\n",
        "        processed_motif_embeddings = self.perceiver_resampler(motif_embeddings)\n",
        "\n",
        "        # Pass through layers (T5Blocks and GatedCrossAttentionBlocks)\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, T5Block):\n",
        "                target_embeddings = layer(target_embeddings)\n",
        "            elif isinstance(layer, GatedCrossAttentionBlock):\n",
        "                target_embeddings = layer(target_embeddings, processed_motif_embeddings)\n",
        "\n",
        "        expanded_sequence = self.expand_seq_len(target_embeddings)\n",
        "        logits = self.protT5_model.lm_head(expanded_sequence)\n",
        "        predicted_token_ids = logits.argmax(-1)\n",
        "\n",
        "        return predicted_token_ids\n",
        "\n",
        "    def generate_protT5_embeddings(self, tokenized_seqs):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.protT5_model(input_ids=tokenized_seqs)\n",
        "        embeddings = outputs.last_hidden_state[0, :len(tokenized_seqs)]\n",
        "        print(\"Generated embeddings shape:\", embeddings.shape)\n",
        "        return embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv7mkV67D5wB"
      },
      "source": [
        "### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WQJHfZpvD4JZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Assuming 'model', 'train_dataloader', 'val_dataloader', 'test_dataloader', and 'criterion' are already defined\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model = model.half() if device.type == 'cuda' else model.full()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Example parameters\n",
        "num_tokens = 28 # protT5 vocab size\n",
        "depth = 3  # Adjust based on model complexity and computational resources\n",
        "\n",
        "model = ProtFlamingoLearnedEmbedding(\n",
        "    num_tokens=num_tokens,\n",
        "    depth=depth,\n",
        "    dim_head=64,\n",
        "    heads=8,\n",
        "    ff_mult=4,\n",
        "    cross_attn_every=2,\n",
        "    perceiver_num_latents=64,\n",
        "    perceiver_depth=2\n",
        ").to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPLbkTa8EIDQ"
      },
      "source": [
        "### **Train Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8iLan9TaEG2u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch_ce(model, data_loader, optimizer, device):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    for one_hot_motifs, tokenized_target_seq, tokenized_binder_seq, _ in tqdm(data_loader, desc=\"Training\"):\n",
        "        tokenized_target_seq = tokenized_target_seq.long().to(device)\n",
        "        tokenized_binder_seq = tokenized_binder_seq.long().to(device)\n",
        "        one_hot_motifs = one_hot_motifs.float().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        model_output = model(tokenized_target_seq, tokenized_binder_seq, one_hot_motifs)\n",
        "        loss = nn.CrossEntropyLoss()(model_output.view(-1, model_output.size(-1)), tokenized_binder_seq.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    print(f\"Training Loss: {average_loss:.4f}\")\n",
        "    return average_loss\n",
        "\n",
        "def validate_epoch_ce(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for one_hot_motifs, tokenized_target_seq, tokenized_binder_seq, _ in tqdm(data_loader, desc=\"Validation\"):\n",
        "            tokenized_target_seq = tokenized_target_seq.to(device).long()\n",
        "            tokenized_binder_seq = tokenized_binder_seq.to(device).long()\n",
        "            one_hot_motifs = one_hot_motifs.to(device).float()\n",
        "\n",
        "            model_output = model(tokenized_target_seq, tokenized_binder_seq, one_hot_motifs)\n",
        "            loss = nn.CrossEntropyLoss()(model_output.view(-1, model_output.size(-1)), tokenized_binder_seq.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    print(f\"Validation Loss: {average_loss:.4f}\")\n",
        "    return average_loss\n",
        "\n",
        "def test_epoch_ce(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for one_hot_motifs, tokenized_target_seq, tokenized_binder_seq, _ in tqdm(data_loader, desc=\"Testing\"):\n",
        "            tokenized_target_seq = tokenized_target_seq.to(device).long()\n",
        "            tokenized_binder_seq = tokenized_binder_seq.to(device).long()\n",
        "            one_hot_motifs = one_hot_motifs.to(device).float()\n",
        "\n",
        "            model_output = model(tokenized_target_seq, tokenized_binder_seq, one_hot_motifs)\n",
        "            loss = nn.CrossEntropyLoss()(model_output.view(-1, model_output.size(-1)), tokenized_binder_seq.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    print(f\"Test Loss: {average_loss:.4f}\")\n",
        "    return average_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Q0w2IwsWNEsR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "94c9ee34-2ac6-431f-fe64-fa17b7f15929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/2500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-cf5aa2318294>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-ceaffb9a4784>\u001b[0m in \u001b[0;36mtrain_epoch_ce\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mone_hot_motifs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_target_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_binder_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtokenized_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_target_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtokenized_binder_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_binder_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mone_hot_motifs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_motifs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss = train_epoch_ce(model, train_dataloader, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    val_loss = validate_epoch_ce(model, val_dataloader, device)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    test_loss = test_epoch_ce(model, test_dataloader, device)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training, Validation, and Test Losses Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OJBI5IltgLPW"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
